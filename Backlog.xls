
<HTML xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:x="urn:schemas-microsoft-com:office:excel">
	<HEAD>
	    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>
			Backlog
		</title>
		<style>@page {mso-header-data: &LBacklog&R; mso-header-margin: .5in; mso-footer-margin: .5in; mso-page-orientation: landscape; margin: 1.0in .75in 1.0in .75in; }
	TABLE { mso-displayed-decimal-separator: "."; mso-displayed-thousand-separator: "," }
	TR { mso-height-source: auto }
	COL { mso-width-source: auto }
	BR { mso-data-placement: same-cell }
	.cell { BORDER-RIGHT: medium none; BORDER-TOP: medium none; FONT-WEIGHT: 400; FONT-SIZE: 10pt; VERTICAL-ALIGN: bottom; BORDER-LEFT: medium none; COLOR: windowtext; BORDER-BOTTOM: medium none; FONT-STYLE: normal; FONT-FAMILY: Arial; WHITE-SPACE: nowrap; TEXT-DECORATION: none; mso-number-format: General; mso-rotate: 0; mso-background-source: auto; mso-pattern: auto; mso-generic-font-family: auto; mso-font-charset: 0; mso-protection: locked visible; mso-style-name: Normal; mso-style-id: 0 }
	TD { BORDER-RIGHT: medium none; PADDING-RIGHT: 1px; BORDER-TOP: medium none; PADDING-LEFT: 1px; FONT-WEIGHT: 400; FONT-SIZE: 10pt; VERTICAL-ALIGN: bottom; BORDER-LEFT: medium none; COLOR: windowtext; PADDING-TOP: 1px; BORDER-BOTTOM: medium none; FONT-STYLE: normal; FONT-FAMILY: Arial; WHITE-SPACE: nowrap; TEXT-DECORATION: none; mso-number-format: General; mso-rotate: 0; mso-background-source: auto; mso-pattern: auto; mso-generic-font-family: auto; mso-font-charset: 0; mso-protection: locked visible; mso-style-parent: cell; mso-ignore: padding }
	H1 { FONT-SIZE: 14pt; FONT-FAMILY: sans-serif }
	H2 { FONT-SIZE: 12pt; FONT-FAMILY: sans-serif }
	.columnheader { BACKGROUND: #dfdfdf; mso-pattern: auto none; mso-number-format: \@; }
	.rowheader { BACKGROUND: #dfdfdf; mso-pattern: auto none }
	/* Leave mso-number-format for data-plain as \@, so that string values that look like dates or numbers aren't mis-interpreted */
	.data-plain { mso-number-format: \@; mso-style-parent: cell }
	.data-longtext { mso-number-format: General; mso-style-parent: cell }
	.data-currency { TEXT-ALIGN: right; mso-number-format: "#,##0"; mso-style-parent: cell }
	.data-amount { TEXT-ALIGN: right; mso-number-format: "#,##0.00"; mso-style-parent: cell }
	.data-percent { TEXT-ALIGN: right; mso-number-format: Percent; mso-style-parent: cell }
	.data-date { TEXT-ALIGN: center; mso-number-format: "Short Date"; mso-style-parent: cell }
	.context-header { TEXT-ALIGN: right; mso-style-parent: cell }
	</style>
		<!--[if gte mso 9]>
	<xml>
		<x:ExcelWorkbook>
			<x:ExcelWorksheets>
				<x:ExcelWorksheet>
					<x:Name>Backlog</x:Name>
					<x:WorksheetOptions>
						<x:FreezePanes/>
						<x:FrozenNoSplit/>
						<x:SplitHorizontal>0</x:SplitHorizontal>
						<x:TopRowBottomPane>0</x:TopRowBottomPane>
						<x:SplitVertical>0</x:SplitVertical>
						<x:LeftColumnRightPane>0</x:LeftColumnRightPane>
					</x:WorksheetOptions>
				</x:ExcelWorksheet>
			</x:ExcelWorksheets>
		</x:ExcelWorkbook>
	</xml>
	<![endif]-->
	</HEAD>
	<body>
		<table>
			<tr>
				<td><table cellspacing="0" cellpadding="0">
	<thead>
		<tr>
			<th class="columnheader">Blocked</th><th class="columnheader">Class of Service</th><th class="columnheader">ID</th><th class="columnheader">Title</th><th class="columnheader">Iteration</th><th class="columnheader">Portfolio Item</th><th class="columnheader">Status</th><th class="columnheader">Estimate Pts.</th><th class="columnheader">Planning Level</th><th class="columnheader">Description</th><th class="columnheader">Order</th><th class="columnheader">Service Class</th><th class="columnheader">Acceptance Criteria (Backlog Item)</th><th class="columnheader">Owner</th><th class="columnheader">Backlog</th><th class="columnheader">Backlog Group</th><th class="columnheader">Backlog Item Status</th><th class="columnheader">Business Priority</th><th class="columnheader">Change Date</th><th class="columnheader">Closed Date</th><th class="columnheader">Code Complexity Rank (0-100):</th><th class="columnheader">Complexity</th><th class="columnheader">Create Date</th><th class="columnheader">Date Completed</th><th class="columnheader">Detail Estimate Hrs.</th><th class="columnheader">Done Hrs.</th><th class="columnheader">Downstream Dependencies</th><th class="columnheader">Iteration State</th><th class="columnheader">Objectives</th><th class="columnheader">Planned Estimate Pts.</th><th class="columnheader">Product Owner</th><th class="columnheader">Split From</th><th class="columnheader">Split From ID</th><th class="columnheader">Tags</th><th class="columnheader">Team</th><th class="columnheader">To Do Hrs.</th><th class="columnheader">Type</th><th class="columnheader">Upstream Dependencies</th>
		</tr>
	</thead><tbody>
		<tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01329</td><td class="data-plain">Split  the 4.2 BO server processes for Functionality</td><td class="data-plain"></td><td class="data-plain">5/29/2019</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator 
I want to configure APS processes on each server to match that server's functionality 
So that the servers work together to handle all requests 
Test Plan: 
Validate CMS servers process logins Validate the Crystal servers process crystal reports Validate the Webi servers  process webi reports 
Acceptance Criteria: 
 CMS servers ,the Crystal servers &amp; the Webi servers are created as needed</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">2.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">2.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01570</td><td class="data-plain">Configure the 4.2 BO WEB/Tomcat Server(s)</td><td class="data-plain"></td><td class="data-plain">5/29/2019</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator 
I want to configure both Web Servers match FedEx environment 
So that the servers provide access to 4.2 BO PROD system 
Test Plan: 
Log onto 4.2 BO Application from each of four 4.2 BO WEB Servers Try logging in and performing functionality testing using different WEB Browsers 
Acceptance Criteria: 
Test plan tasks complete successfully</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">2.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">2.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01607</td><td class="data-plain">Server Install the 4.2 Business Objects Application Software</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">5/29/2019</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator 
I want to install 4.2 BO software on PROD Servers
So that we have 4.2 BO installed on all PROD servers. 
Test Plan: 
Installation Script completes successfully, displays successful install message on each server
Acceptance Criteria: 
Can Log into BO 4.2 Once Cluster is Complete</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">14.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount">14.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01002</td><td class="data-plain">Correct HELP section access in AB applications</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01004</td><td class="data-plain">OVO log monitoring and ePDSM ticket creation (critical incidents)</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01163</td><td class="data-plain">AB-I: PROD Architecture Diagram of the new Cloud Environment</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
  
I want: to create an architecture diagram of the new cloud environment. 
  
So that: PROD will be created in the new cloud environment and the nodes and the content of those will be identified.   
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">24.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">18.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01164</td><td class="data-plain">AB-I: QA Architecture Diagram of the new Cloud Environment</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
  
I want: to create an architecture diagram of the new cloud environment. 
  
So that: QA will be created in the new cloud environment and the nodes and the content of those will be identified.   
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">24.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">18.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01197</td><td class="data-plain">Disk evaluation</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Evaluate disk allocation settings 
So that: Confirmation of storage parameters meeting the Vendors specifications 
A/C: Disk allocation meet vendors recommendations</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01350</td><td class="data-plain">Change reporter run function from Single User Mode to Functional User Mode</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner  
I want: To Change reporter run function from Single User Mode to Functional User Mode 
So that: It will eliminate the redundant workload being performed by both of these reporters. 
Test plan:  
Acceptance Criteria:  
Allow host and product monitoring to be done by only 1 reporter.  Info here: Control&gt;Center Help -&gt; Administrator’s Guide -&gt; PART ONE: Setting up Control&gt;Center -&gt; Configuring functional user account support</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01355</td><td class="data-plain">Storage maintenance for Ab Initio log files</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01438</td><td class="data-plain">Connectivity to external data sources</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Confirm that Teradata/Oracle/Hadoop connections are established 
So that: Ab Initio can successfully interface with external data sources 
A/C: Connectivity to external sources from the new cloud server</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01444</td><td class="data-plain">Create project folders *Talk with Skynet</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: AB Developer  
I want: create project folders for Skynet  
So that: Can Develop new requirements Skynet. 
A/C: all project data directories from SP AB cluster exist. 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01451</td><td class="data-plain">Disk evaluation</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Evaluate disk allocation settings 
So that: Confirmation of storage parameters meeting the Vendors specifications 
A/C: Disk allocation meet vendors recommendations</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01454</td><td class="data-plain">Existing PROD Co-operating system upgrade</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Upgrade the existing Ab PROD environment from 3.3.2.3 to version 3.3.3.11 
So that: We can utilizing the existing EME and Control center moving forward 
A/C:  Run AB commands to validate the existing EME and Control center.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01475</td><td class="data-plain">Passwordless server setup</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Configure a Passwordless setup on all servers 
So that: SSH connections can be made without needing a password 
A/C: Show that SSH connections can be made between the nodes</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01510</td><td class="data-plain">Validation Testing</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Complete validation testing of the new QA Ab Initio environment 
So that: We can confirm that EME, GDE, and Control Center are performing properly 
A/C: Successful execution of graphs.  Check-in and checkout of code. Test jobs of restarting servers.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01511</td><td class="data-plain">Validation Testing *TALK with Skynet</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Complete validation testing of the new PROD Ab Initio environment 
So that: We can confirm that EME, GDE, and Control Center are performing properly 
A/C: Successful execution of graphs.  Check-in and checkout of code. Test jobs of restarting servers.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01596</td><td class="data-plain">Oracle DB maintenance for Ab Initio schema</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner  
I want: Oracle Database Maintenance for Ab Initio Schema 
So that: the DBA can periodically run Oracle Segment Advisor, as well as generate stats on a continuous basis 
Test plan:  
Acceptance Criteria:  
DBA Is able to check fragmentation 
Defragmentation and a fresh copy of statistics will allow the database to function at an optimal level. Allow this to occur after the purging of log files.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01598</td><td class="data-plain">Setup of manual and continuous jobs within the QA Ab Initio environment</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner 
I want:  Setup manual and continuous jobs within the QA Ab Initio environment 
So that: Proper testing can be conducted whenever upgrades or patching to Control Center occurs.  Jobs can be held in a wait status, and released as needed for testing. 
Test plan:  
Acceptance Criteria: In QA proper testing can be conducted whenever upgrades or patching to Control Center occurs.  Jobs can be held in a wait status, and released as needed for testing.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01671</td><td class="data-plain">Apphub and Abinitiorc configuration</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Identify the work and data directories 
So that: apphubrc &amp; abinitiorc and be configured properly 
A/C: AB home settings match vendors recommendation</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01674</td><td class="data-plain">Bridge and Reporter configuration</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Establish the bridge and reporter configurations within the cluster 
So that: Web and run server hosts can communicate properly 
A/C: Bridge and reporter services for new cluster can be seen within Control center</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01677</td><td class="data-plain">Build Multifle system</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Build the MFS file system on each server 
So that: The proper file structures and partitioning methods are established 
A/C: Multiple partition are present for each file.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01681</td><td class="data-plain">Connectivity to external data sources</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Confirm that Teradata/Oracle/Hadoop connections are established 
So that: Ab Initio can successfully interface with external data sources 
A/C: Connectivity to external sources from the new cloud server</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01684</td><td class="data-plain">Create application users</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team to create all necessary application users on all new Ab Initio servers 
So that: The following user accounts can exist: sbiQA, sbiqas, sbiown  and abadmin 
A/C: user accounts exist: sbiQA, sbiqas, sbiown  and abadmin</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01690</td><td class="data-plain">Create sudo role</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team that the abinitiocm sudo role is created on all new Ab Initio servers 
So that: I have the required permissions and roles to complete my job 
A/C: Have the permission and sudo roles</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01716</td><td class="data-plain">Oracle DB connection</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Establish a connection to the Oracle database repository 
So that: Control center can utilize the existing database 
A/C: Connection to the oracle db</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01738</td><td class="data-plain">Request mount points</td><td class="data-plain"></td><td class="data-plain">AAA: AI - Fortification of Ab Initio environment</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team to modify the mount points to reflect the vendors recommendations 
So that: The cloud Abinitio cluster is sized properly. 
A/C: AB cluster is sized to the vendors recommendations. /var/fedex 500gb, /opt/fedex 50 gb</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01010</td><td class="data-plain">Research BI application options (Java/Abinitio/etc) to retrieve data from HR API’s.</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Define HR data consumption and delivery architecture for the Employee database</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01600</td><td class="data-plain">Conduct POC to verify new application meets analytical, reporting, and data acquisition needs</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Define HR data consumption and delivery architecture for the Employee database</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01601</td><td class="data-plain">Design or select new BI application, including translation rules and frequencies</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Define HR data consumption and delivery architecture for the Employee database</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01603</td><td class="data-plain">Complete data mapping of EMP schema objects to HR data hub repository</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Discover HR Datahub data needs in support of existing BI applications</td><td class="data-plain">Options</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Edward Obringer</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01604</td><td class="data-plain">Identify data elements (tables/columns) needed to support BO and eForm applications</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Discover HR Datahub data needs in support of existing BI applications</td><td class="data-plain">Options</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01605</td><td class="data-plain">Information sharing with Field News Website and SAS supporting group</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Discover HR Datahub data needs in support of existing BI applications</td><td class="data-plain">Options</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01606</td><td class="data-plain">Select or assist in the definition of HR Datahub API’s for the FXG service clients</td><td class="data-plain"></td><td class="data-plain">AAA: AI - HR Datahub - Discover HR Datahub data needs in support of existing BI applications</td><td class="data-plain">Options</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01878</td><td class="data-plain">Split  the 4.2 BO server processes for Functionality</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - 4.2 L4/Prod Install</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Business Objects Administrator <br>I want to configure APS processes on each server to match that server's functionality <br>So that the servers work together to handle all requests <br>Test Plan: <br>Validate CMS servers process logins Validate the Crystal servers process crystal reports Validate the Web servers  process webi reports <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> CMS servers are created as needed  the Crystal servers are created as needed  the Web servers are created as needed<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01879</td><td class="data-plain">Configure the 4.2 BO WEB System</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - 4.2 L4/Prod Install</td><td class="data-plain">Options</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Business Objects Administrator <br>I want to configure both Web Servers to match FedEx environment <br>So that the servers provide access to 4.2 BO L4/QAelopment system <br>Test Plan: <br>Log onto 4.2 BO Application from each of two 4.2 BO WEB Servers Try logging in and performing fucntionality testing using different WEB Browsers <br>  <br>** Swarm all 4 BO Admins on doing this<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Test plan tasks complete successfully<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01880</td><td class="data-plain">Server Install the 4.2 Business Objects Application Software</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - 4.2 L4/Prod Install</td><td class="data-plain">Working on It</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Business Objects Administrator <br>I want to install 4.2 BO software on L4/QA Servers<br>So that we have 4.2 BO installed on all QA servers. <br>Test Plan: <br>Installation Script completes successfully, displays successful install message on each server<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Can Log into BO 4.2 Once Cluster is Complete<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01022</td><td class="data-plain">SPIKE: BO 4.2 Prod Planning</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - 4.2 L4/Prod Install</td><td class="data-plain">Working on It</td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a: BO Administrator 
I want: to investigate installing BO 4.2 Production in Pittsburgh Vs. Alternative Data Center 
So that: We can avoid performing duplicate installations in multiple data centers 
Acceptance Criteria: Determine our future body of stories for BO 4.2 Installation</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">1.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">1.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01885</td><td class="data-plain">Test Using 360 Plus to load BO 4.2</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">AAA: BO - Add Production Content to BO 4.2 L4/QA</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a: Business Objects Administrator<br><br>
I want: testing using 360 Plus to load User data<br><br>
So that: the documentation will enable the Vendor to perform the task<br><br>
Test plan: Run the task using documentation<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Manager Approval of the documentation<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01330</td><td class="data-plain">Spike: Develop Business Objects 4.2 Training</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">AAA: BO - BO 4.2 PRODUCTION STANDARDS</td><td class="data-plain">Options</td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a BO Administrator<br><br>
I want to develop a training plan for Business Objects Users within 5 days<br><br>
So That BO Users can learn how to use BO 4.2<br><br>
Acceptance Criteria: A Training plan is documented and a training story is built after 5 days<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">4.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">4.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01573</td><td class="data-plain">Configure LDAP Configuration</td><td class="data-plain"></td><td class="data-plain">AAA: BO - BO 4.2 PRODUCTION STANDARDS</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator 
I want to configure the LDAP settings 
So that I can so I can log in using Ldap account 
Test Plan: 
Try an log in using Ldap Account 
Acceptance Criteria: 
Confirm Business Objects 4.2 log in successfully logged into BO 4.2 system</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">4.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">4.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01574</td><td class="data-plain">Install App Dynamics on WEB Servers</td><td class="data-plain"></td><td class="data-plain">AAA: BO - BO 4.2 PRODUCTION STANDARDS</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a BO Administrator 
I Want to install AppDynamcis on the Web Servers 
So that we can monitor BO web server performance 
Test Plan: 
AppD performance metrics are displaying properly for each web server 
Acceptance Criteria: 
AppD performance metrics are displaying properly for each web server</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">11.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">3.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01575</td><td class="data-plain">Install GB &amp; Smith 360 Plus Tool</td><td class="data-plain"></td><td class="data-plain">AAA: BO - BO 4.2 PRODUCTION STANDARDS</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator 
 
 I want the 360 Plus tool installed
 
 So that I can schedule backups of 4.2 BO 
 
 Test Plan:
 
 Confirm you can access tool menu
 
 Acceptance Criteria:
 
 You can access tool menu</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">2.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">1.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01576</td><td class="data-plain">Schedule backups using  GB &amp; Smith 360 Plus Tool</td><td class="data-plain"></td><td class="data-plain">AAA: BO - BO 4.2 PRODUCTION STANDARDS</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator 
 
 I want the 360 Plus tool installed
 
 So that I can schedule backups of 4.2 BO 
 
 Test Plan:
 
 Confirm Scheduled Full backup completes
 
 Confirm Scheduled Incremental backup completes
 
 Confirm object recovery by recovering object(s)
 
 Acceptance Criteria:
 
 Confirm Scheduled Full backup completes
 
 Confirm Scheduled Incremental backup completes
 
 Confirm object recovery recovers object(s)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">2.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">2.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02212</td><td class="data-plain">BO 4.2 Production Standards</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">AAA: BO - BO 4.2 PRODUCTION STANDARDS</td><td class="data-plain">Refinement</td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As the BO IT Manager <br>I want to confirm current FedEx BO functionality works in BO 4.2 Prod <br>So that: We can continue using Business Objects as we currently are in BO 4.1 <br>  <br>Business Value/Cost of Delay: <br>We wont lose functionality or change when 4.1 is out of support<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01882</td><td class="data-plain">BO-Submit requests for NAS Spaces and NFS Mounting  L4/QA</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - Configure BO 4.2 in QA</td><td class="data-plain">PM Acceptance</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a Business Objects Administrator <br>I want to <br>Submit requests for NAS Spaces and NFS Mounting L4/QA <br>So that <br>NAS Spaces mounted to the BO Servers <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Business Object User has read/write access to the NAS Space<br><br></td><td class="data-plain">Huiyun Gu</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date">03/19/2019</td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01881</td><td class="data-plain">BO-Submit requests for Database Schemas (11g) L4/QA</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - Configure BO 4.2 in QA</td><td class="data-plain">Options</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Business Objects Administrator <br>I want to <br>Submit requests for Database Schemes and Drivers (11g) L4/QA <br>So that <br>The Schema exists and driver is installed, and both meet BO's requirements<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Have an empty Schema <br> Schema Owner has requested permissions (Grants) <br> Driver installed in /opt/oracle directory<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01883</td><td class="data-plain">BO-Submit request for Load Balancer     L4/QA</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">AAA: BO - Configure BO 4.2 in QA</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Objects Administrator <br>I want to <br>Submit request for Load Balancer L4/QA <br>So that <br>Load Balancer brings up business objects login dynamic l using one of four Tomcat Servers <br><br><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Login comes up on all four Tomcat Servers / dynamically selects the server via manual, scripting, and Lode Runner testing<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01884</td><td class="data-plain">Configure BO 4.2 in L4/QA</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - Configure BO 4.2 in QA</td><td class="data-plain">Options</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As the BO IT Manager <br>I want to confirm current FedEx BO functionality works in BO 4.2 L4/QA <br>So that: We can continue using Business Objects as we currently are in BO 4.1 <br>  <br>Business Value/Cost of Delay: <br>We wont lose functionality or change when 4.1 is out of support<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Properly configured to work with all of our existing data sources. <br>Test BO 4.1 Functionality on the BO 4.2 servers<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01915</td><td class="data-plain">Resolve the issue of crystal servers losing connection</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: BO - Operational Excellence CY 19.1</td><td class="data-plain"></td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Business Objects Administrator<br><br>
I want to<br><br>
Resolve the issue of crystal servers losing connection<br><br>
So that it does not lose connections anymore and kill crystal report<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Work with SAP for resolution<br><br>
Monitor situation through PI 5.<br><br></td><td class="data-plain">Harold Moon</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01280</td><td class="data-plain">Documentation on Fiscal Year End process for SVM Universes and Reports</td><td class="data-plain"></td><td class="data-plain">AAA: BO - SVM Fiscal Year End Process for Universes Documented</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01769</td><td class="data-plain">Data Studio best practices</td><td class="data-plain"></td><td class="data-plain">AAA: MVP - Data Studio usage framework development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01770</td><td class="data-plain">Data Studio discovery</td><td class="data-plain"></td><td class="data-plain">AAA: MVP - Data Studio usage framework development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01771</td><td class="data-plain">Data Studio usage framework development</td><td class="data-plain"></td><td class="data-plain">AAA: MVP - Data Studio usage framework development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01772</td><td class="data-plain">Framework review</td><td class="data-plain"></td><td class="data-plain">AAA: MVP - Data Studio usage framework development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01288</td><td class="data-plain">Test dataset</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO data development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01773</td><td class="data-plain">Analyze data set and discuss details with Integration team</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO data development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01774</td><td class="data-plain">Develop business ready data for analysis (BigQuery, DataPrep?)</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO data development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01775</td><td class="data-plain">Implement architecture in GCP to enable MVP development</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO data development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01291</td><td class="data-plain">Test developed dashboards</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO Visualization development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01777</td><td class="data-plain">Develop dashboard based on requirements in Data Studio</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO Visualization development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01778</td><td class="data-plain">Review and deploy dashboards</td><td class="data-plain"></td><td class="data-plain">AAA: MVP – DRO Visualization development</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a:  
I want:  
So that:  
Test plan:  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01917</td><td class="data-plain">SPIKE: SAS App Rationalization and QDM Process Improvement</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SAS - Current State Data Flow Assessment</td><td class="data-plain">Options</td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a:  AAA Product Owner<br><br>
I want: QDM Process Improvement in place for SAS User Account Requests<br><br>
So that: AAA can receive a recommendation for SAS User Account Requests Improvement<br><br>
Test plan: <br><br>
Dependencies:<br><br>
Catherine Mayhew<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">A plan to improve the process for the SAS User Account Creation<br><br></td><td class="data-plain">Edward Obringer</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01555</td><td class="data-plain">Implement the new Structure</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin -  Access Management Implementation/New Group Transition</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: SF Architect<br><br>
I want: To implement the new spotfire component licensing Structure<br><br>
So that: We can assign the right credentials to each persona groups<br><br>
 <br><br>
Test plan: <br><br>
Validate that the correct licenses are assigned to the correct persona group.<br><br>
 <br><br>
Acceptance Criteria: Correct credentials assigned to each group. Dependencies:<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01802</td><td class="data-plain">Test Assigned license credentials for every persona</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin -  Access Management Implementation/New Group Transition</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: SF Architect<br><br>
I want: Test Assigned license credentials for every persona<br><br>
So that: we can compare the credentials with the assigned license credentials for every persona to verify that the license is accurate.<br><br>
 <br><br>
Test plan: compare the credentials with the assigned license credentials for every persona to verify that the license is accurate.<br><br>
 <br><br>
Acceptance Criteria: License credentials meet the expectations that we have identified in the design document.<br><br>
 <br><br>
Dependencies: Functionality is enabled for each group.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01800</td><td class="data-plain">Migrating 1 new group</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin -  Access Management Implementation/New Group Transition</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: SF Architect<br><br>
I want: to Migrate 1 image group (read, write and owner) to the new structure<br><br>
So that: We can test the access levels between consumers/bi developers/citizen data scientists/administrators<br><br>
 <br><br>
Test plan: All four AD groups (create a citizen data scientist) are assigned to the related persona and credentials and functionality is validated with the business team.<br><br>
 <br><br>
Acceptance Criteria: All four AD groups are created for the team and the business team validated their access levels.<br><br>
 <br><br>
Dependencies: Working with the new AD group on their access levels/validation/availability.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01557</td><td class="data-plain">Migrating the rest of the new groups to the new role structure</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin -  Access Management Implementation/New Group Transition</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: SF Architect 
I want: Migrate the rest of the "new" (the groups using the FXG_SPOTFIRE_"BUSINESS GROUP AD STRUCTURE") groups to the new role structure 
So that: We have all of the new AD groups assigned with the new Role structure for the personas inside of the AD group 
Test plan: All four AD groups are created for the team and the business team validated their access levels. 
Acceptance Criteria: All four AD groups are created for the team and the business team validated their access levels. 
Dependencies: Working with the new AD group on their access levels/validation/availability. 
Communication needs to take place before and after the change to ensure that the business area's are compliant and understanding of what is taking place with the new roles/persona's</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01554</td><td class="data-plain">Business AD Group Excel Documentation</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin -  Access Management Implementation/New Group Transition</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: SF Architect 
I want:  A document identifying all of the business AD Groups 
So that: We can have an inventory of all of the business area's that we have inside of Spotfire and their roles/personas 
Test plan: Document created with the information that is needed to identify the business/manager/persona's of the AD group. 
Acceptance Criteria: Document created with the information that is needed to identify the business/manager/persona's of the AD group. 
Dependencies: Working with the AD Groups to get the information needed to fill out the documentation.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01316</td><td class="data-plain">Install of new version (7.0.7) ADS</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - ADS Update on Dev (L2)</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Spotfire Admin 
I want: to install the new version (7.0.7) of ADS on L2 
So that: we can have the updated version 
Business Value: the software is ready to be used for further analysis of functionalities 
Test Plan: Validate software installation and access 
Acceptance Criteria: Software is successfully installed (test plan completed) and current users can login</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01803</td><td class="data-plain">Create DB backup of the current version of ADS</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - ADS Update on Dev (L2)</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Spotfire Admin 
I want: to create a backup the the ADS database 
So That: in case of restore we will have all the necessary information and data available to restore the current version 
Business Value: Easy restore to current version in case of failure 
Test Plan: Validate that backup files are successfully created 
Acceptance Criteria: Validate that backup files are successfully created</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 1</td><td class="data-plain"></td><td class="data-plain">B-01922</td><td class="data-plain">Install AppD in Windows Servers (PROD)</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - App D Metrics</td><td class="data-plain">Dependency Management</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Spotfire Admin<br><br>
I want AppD Installed on Windows Servers<br><br>
So that We can monitor usage of Windows Servers where WebPlayer is installed<br><br>
Dependencies<br>Application Dynamics Team<br>Windows-SA/ Dennis Angel<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">AppD is installed in Windows Servers and tested by Windows SA and Spotfire Admins<br><br>
AppD is installed in Windows Servers, configured, and working as expected in PROD<br><br>
 <br><br></td><td class="data-plain">Otabek Kurbonov (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01923</td><td class="data-plain">Create APPDYNAMICS Dashboard</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - App D Metrics</td><td class="data-plain">PM Acceptance</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a : Spotfire Admin<br><br>
I want to: Create dashboard in APPD to visualize Businesss Transaction metrics i.e Load, Response Times, Errors and Transaction Score Card<br><br>
So that: AAA team can see the dashboard from APM Portal and analyze the node health status<br><br>
Test Plan: AAA team has access to the dashboard and able to analyze the metrics<br><br>
Dependencies<br><br>
App-D Admin Team<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> <br><br>

    • The dashboard should contain key performance metrics such as number of calls/min, slow response times and errors<br>
    • AAA able to access the dashboard and view the data<br>
</td><td class="data-plain">Aniket Parab (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date">03/13/2019</td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01577</td><td class="data-plain">PDSM Template</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - EPDSM</td><td class="data-plain">Options</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a: AAA Product Owner 
I want: the PDSM Template filled out and turned into Louellen Mills &amp; the PDSM Asset Management Team 
So that: We can get the EPDSM template created by the PDSM Asset Management team 
Test plan: Having the EPDSM template filled out and sent into PDSM Asset management for them to create the Questionnaire/User Template for EPDSM for the new assignment group. 
Acceptance Criteria: Having the EPDSM template filled out and sent into PDSM Asset management for them to create the Questionnaire/User Template for EPDSM for the new assignment group. 
Dependencies: PDSM Asset Management</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01578</td><td class="data-plain">Process Flow/Design</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - EPDSM</td><td class="data-plain">Options</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a: AAA Product Owner  
I want: a Process Flow/Design Diagram 
So that: We have documentation on the process that we'll be implementing for the new EPDSM Assignment Group 
Test plan: Have a documented flow of the new process for the requests to the new EPDSM assignment group. 
Acceptance Criteria: Have a documented flow of the new process for the requests to the new EPDSM Assignment Group. 
Dependencies: N/A</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01579</td><td class="data-plain">Set up Assignment Group</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - EPDSM</td><td class="data-plain">Options</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Product Owner 
I want a combined/Global Assignment Group created 
So that When analytics requests come through for AAA we have a combined queue of all requests to be distributed amongst AAA 
Acceptance Criteria: An assignment group created for AAA Analytic requests. 
Dependencies: Louellen Mills &amp; the PDSM Asset Management team. 
Prerequisite: Identify and finalize the workflow of Prioritization.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01338</td><td class="data-plain">Create Load Balancer for Spotfire L2 (continued from story #388638)</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled Development Environment</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Spotfire Admininstrator 
I want: to create a Load Balancer  
So That: all the 4 linux servers are utilized via the load balancer 
Business Value: Server utilization will be managed by the load balancer and in case of server failure cluster is still available 
Test Plan(s): Test the load balancer whether it utilizes every node available in the cluster 
Acceptance Criteria: 
 
Load balancer has been created.  
Load is balanced on the server when users log onto the web player and it is shared between nodes. 
 
  
Note:  Had to stop with Load balancer because of no room in PGH and moving to WTC/EDCW Data Centers.  Need to readjust and determine the scope for getting our servers into another DCO/Cloud...</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Aniket Parab (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">12.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">12.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01339</td><td class="data-plain">Installing SSL Certificates</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled Development Environment</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Spotfire Administrator 
I want: to install new SSL certificates on the all additional servers 
So That: the communication between servers and clients are secured 
Business Value: Secured communication for any requests going through the servers 
Test Plan(s): validating URL HTTPS status 
Acceptance Criteria: All communications are proved to be via HTTPS using the installed SSL certificates</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Aniket Parab (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">22.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">22.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01582</td><td class="data-plain">Update Server Documentation</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled Development Environment</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: BI Architect 
I want: to document all the cluster/server changes 
So That: FXG has an up-to-date architecture description available 
Business Value: Architecture document will help to socialize server information and structure 
Test Plan(s): Document needs to be verified by Admins and Architects 
Acceptance Criteria: Document passed vaildation and published on FXG Spotfire Sharepoint folder 
  
Note:  Had to stop with Load balancer because of no room in PGH and moving to WTC/EDCW Data Centers.  Need to readjust and determine the scope for getting our servers into another DCO/Cloud...</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Aniket Parab (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">14.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">7.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01918</td><td class="data-plain">Modify and test the existing load balancer to utilize vrh56011 server.</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled QA Environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Spotfire Administrator<br><br>
I want: to Modify and test the existing load balancer<br><br>
So that: I can utilize the vrh56011 server<br><br>
Test plan: Using the csm.html file to check if the vrh56011 server is utilized by the load balancer.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Using the csm.html file to check if the vrh56011 server is utilized by the load balancer.<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01919</td><td class="data-plain">Configure the newly added servers to use the load balancer SSL certificates.</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled QA Environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Spotfire Administrator<br><br>
I want: to configure the newly added servers in the QA environment<br><br>
So that: they can use the load balancer SSL certificates<br><br>
Test plan: Modify the server.xml file and copy the load balancer certificates onto the server<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">the current load balancer SSL certificates are added and visible on the QA servers.<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01920</td><td class="data-plain">Modify and verify the configurations of newly added servers are same as existing servers in the cluster.</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled QA Environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Spotfire Administrator<br><br>
I want: to modify and verify the configurations of the newly added servers <br><br>
So that: they are the same configurations as the existing servers in the cluster<br><br>
Test plan: Verifying that the same configurations on the newly added servers are the same as the rest of the servers in the cluster.  This includes configuration for maps on webplayer server and other settings related to the webplayer servers and automation services. <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">The configurations on all of the QA servers are the same.<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01921</td><td class="data-plain">Update Server documentation.</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Scaled QA Environment</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: BI Architect<br><br>
I want: to document all the cluster/server changes<br><br>
So That: FXG has an up-to-date architecture description available<br><br>
Business Value: Architecture document will help to socialize server information and structure<br><br>
Test Plan(s): Document needs to be verified by Admins and Architects<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> <br><br>
Document passed vaildation and published on FXG Spotfire Sharepoint folder<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01934</td><td class="data-plain">Server 7.11.2. Patch on Dev</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Server 7.11.2 Patch</td><td class="data-plain">Working on It</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As the Product Owner<br><br>
I want Spotfire patched to version 7.11.2 in Dev.<br><br>
So that Spotfire can be upgraded to server 7.11.2 to address Security concerns that we're recently identified in versions 7.11.0 and 7.11.1.  <br><br>
Business Value/Cost of Delay: <br><br>
<span style="font-size: 11pt; font-family: 'calibri' , sans-serif; color: #1f497d;">TIBCO released three security alerts this week that impacted on Spotfire server version 7.11.1, 7.11.0 we deployed.</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Upgrade Software to version Spotfire Server 7.11.2 in Dev.<br><br></td><td class="data-plain">Aniket Parab (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01926</td><td class="data-plain">Design and develop Van scan accuracy and Compliance view of the dashboard</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"><span style="background-color: #ffffff;">As a: IT Manager</span><br><br>
<span style="background-color: #ffffff;">I want: The Van Scan Accuracy and Compliance dashboard to display the KPI &amp; line chart</span><br><br>
<span style="background-color: #ffffff;">So that: It represents VSA &amp; VSC</span><br><br>
<span style="background-color: #ffffff;">Test plan: Dashboard displays the KPI chart and line chart with the accurate VSA &amp; VSC for selected time period and facility</span><br><br>
<span style="background-color: #ffffff;">Dependencies: N/A</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="background-color: #ffffff;">Dashboard displays the KPI chart and line chart with the accurate VSA &amp; VSC</span><br><br></td><td class="data-plain">Venkata Yerasi,Punit Bhatt</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01928</td><td class="data-plain">Applying Defaults to Dropdown Time Period Filters -Part 1</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a: Station Reporting dashboard developer/power user <br><br>
I want: the Spotfire connection for the OPRPT prod database created in the Prod Spotfire environment<br><br>
So that: Defaults will be set at the current date, week, month, year, allowing users a more efficient and convenient experience<br><br>
Test plan: Ensure all defaults at current date, week, month, year displays and displays accurately and all the metrics charts and KPIs refresh<br><br>
Dependencies: <br><br>
Python / Java Scripting Team Member<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Ensure all defaults at current date, week, month, year displays and displays accurately and all the metrics charts and KPIs refresh<br><br></td><td class="data-plain">Venkata Yerasi,Punit Bhatt</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01929</td><td class="data-plain">Develop the Consolidated OTS view screen</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Working on It</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a: Station Reporting User<br><br>
I want: Consolidated OTS View Screen Metrics to be displayed for each IORG level.<br><br>
So that: I can see view all dependent child IORGs under the selected parent IORG<br><br>
Test plan: All Child IORGS along with their KPIs needs to be correctly displayed for their selected parent IORG<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">All Child IORGS along with their KPIs needs to be correctly displayed for their selected parent IORG<br><br></td><td class="data-plain">Venkata Yerasi,Punit Bhatt</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01930</td><td class="data-plain">Develop the Consolidated Prod view screen</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a: Station Reporting User<br><br>
I want: Consolidated Productivity View Screen Metrics to be displayed for each IORG level.<br><br>
So that: I can see view all dependent child IORGs under the selected parent IORG<br><br>
Test plan: All Child IORGS along with their KPIs needs to be correctly displayed for their selected parent IORG<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> <br><br>
Acceptance Criteria: All Child IORGS along with their KPIs needs to be correctly displayed for their selected parent IORG<br><br></td><td class="data-plain">Venkata Yerasi,Punit Bhatt</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01932</td><td class="data-plain">Monitor Station Reporting and PROD Servers</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Spotfire Admin<br><br>
I want to monitor PROD environment status and check log files. Monitor Station Reporting dashboard<br><br>
So that the servers and dashboard is up and running<br><br>
The server logs and dashboard is monitored and documented<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Monitor PROD environment status<br><br>
Monitor Station Reporting Dashboard<br><br>
Operational Reporting Database doesn't get locked.<br><br></td><td class="data-plain">Otabek Kurbonov (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02203</td><td class="data-plain">SR - Formatting Landing Page</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02204</td><td class="data-plain">SR- Formatting Prod detail View screen</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Product Owner<br><br>
I want station reporting turned on in production<br><br>
So that Ground Engineering, Field Users and Administration can access Station Reporting in the field.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02205</td><td class="data-plain">SR-Formatting OTS detail (IB and OB) screens</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Product Owner<br><br>
I want station reporting turned on in production<br><br>
So that Ground Engineering, Field Users and Administration can access Station Reporting in the field.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02206</td><td class="data-plain">SR-Formatting Consolidated OTS  view</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Product Owner<br><br>
I want station reporting turned on in production<br><br>
So that Ground Engineering, Field Users and Administration can access Station Reporting in the field.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02207</td><td class="data-plain">SR-Performance testing in QA</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Product Owner<br><br>
I want station reporting turned on in production<br><br>
So that Ground Engineering, Field Users and Administration can access Station Reporting in the field.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02211</td><td class="data-plain">Applying default Time period Filters -Part 2</td><td class="data-plain"></td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a Product Owner<br><br>
I want station reporting turned on in production<br><br>
So that Ground Engineering, Field Users and Administration can access Station Reporting in the field.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01933</td><td class="data-plain">Promote Station Reporting  from QA to PROD</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">AAA: SF Admin - Station Reporting</td><td class="data-plain">Options</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Spotfire Admin<br><br>
I want to promote Station Reporting dashboard from QA to PROD.<br><br>
So that the dashboard is available for business users.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> <br><br>
The dashboard is promoted to PROD and running.<br><br>
 <br><br></td><td class="data-plain">Otabek Kurbonov (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01583</td><td class="data-plain">Validate OVO Alerting</td><td class="data-plain"></td><td class="data-plain">AAA: SF Support - OVO Alerting</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: BI Architect 
I want: to validate OVO capabilities and integration options 
So that: we can identify OVO functions and business value for Spotfire Environments 
Test Plan: N/A 
Acceptance Criteria: Functionality list is ready and plan is identified in case OVO extends Appdynamics functionality and value</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01342</td><td class="data-plain">Research HP OpenView tool capabilities and install requirements</td><td class="data-plain"></td><td class="data-plain">AAA: SF Support - Windows Server Monitoring</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: BI Architect 
I want: to investigate the HP OpenView capabilities (meet with Bill Settino) 
So That: we understand the functionalities and prerequisites of the tool 
Business Value: Server monitoring functionalities can be verified before installation 
Test Plan: List of functionalities are created and software is verified against business needs 
Acceptance Criteria: List of functionalities are created and software is verified against business needs</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01935</td><td class="data-plain">BO - Pausing Service Explanation Same-Day for 2 regions</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount">0.10</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Product Owner<br><br>
I want:"BO 4.1/Public Folders/GROUND/ROOT CAUSE REPORTS FOLDER/Service Explanation Same-Day" need the "East/Mid-America/West (2 Hour Earlier)" and "Central Same Day (2 Hour Early Release)" schedule to be paused. Additionally, "Central Same Day" needs to turn off saving the instance after the schedule has run.<br><br>
So That: These schedules do not need to be running but they would like to be kept incase the reports needed to be turned on in the future<br><br>
Central Same Day (2 Hour Early Release) schedule is paused<br><br>
Central Same Day needs to be turned off.<br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Joshua LaGrange RFS</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">East/Mid-America/West (2 Hour Earlier) schedule is paused<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01936</td><td class="data-plain">BO - 3 Reports that need to be Extracted as Excel</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner<br><br>
I want: To export 3 reports<br><br>
So that: They are exported as excel data only the headers mix up, reports include: ScannerDataLogin.rpt, ScannerLoginData_Station.rpt, and all others under LCU folder.<br><br>
 <br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Marika Austin RFS</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Export the following reports to excel: ScannerDataLogin.rpt, ScannerLoginData_Station.rpt, and all others under LCU folder.<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01972</td><td class="data-plain">2 New Linehaul Data Reports</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">AS a Product Owner<br><br>
I want: to C<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">reate 2 new reports for Linehaul Data located here:Public Folders/GROUND FOLDER/LCU</span><br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">So That: Marika Austin can  have the same reports for Linehaul data that they currently have for Scanner Data such as: 1. Linehaul by Station ID (prompt to be consistent with the ScannerLoginData_Station.rpt) 2. Linehaul by ID (prompt to be consistent with ScannerLoginData_ID.rpt)</span><br><br>
 <br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;"><span>Marika Austin RFS</span></span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Creating 2<span> </span>new reports for Linehaul Data located here:Public Folders/GROUND FOLDER/LCU We are looking to have the same reports for Linehaul data that we currently have for Scanner Data such as: 1. Linehaul by Station ID (prompt to be consistent with the ScannerLoginData_Station.rpt) 2. Linehaul by ID (prompt to be consistent with ScannerLoginData_ID.rpt)</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01973</td><td class="data-plain">BO - Correct data with the pkgfraud = RTH and Fraud Universes</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner<br><br>
I want: To export 3 reports<br><br>
So that: They are exported as excel data only the headers mix up, reports include: ScannerDataLogin.rpt, ScannerLoginData_Station.rpt, and all others under LCU folder.<br><br>
 <br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Marika Austin RFS</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Export the following reports to excel: ScannerDataLogin.rpt, ScannerLoginData_Station.rpt, and all others under LCU folder.<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01974</td><td class="data-plain">BO - MMR Compliance Report on the Station Level.</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner<br><br>
I want: <span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">A BO Report created</span><br><br>
So that: we can capture the MMR compliance on the station level.<br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Kelly Prohaska RFS</span></td><td></td><td class="data-plain"></td><td class="data-longtext"> <span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">A report  created to capture MMR compliance on the station level.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01975</td><td class="data-plain">Contractor Station Reviews Report</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a Product Owner<br><br>
I want: <span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">District Scale Review Field Reporting-P&amp;D Engineering-Scale Folder Would like monthly or real time report available</span><br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">So that: They can review station specific scale at CSP level. Current process is overlay manual</span><br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Information required for Contractor Station Reviews in an effort to assist with Overlap acceleration and scale awareness</span></td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Provide a </span><span> </span><span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">monthly or real time report available that</span><span> </span><span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;"> can be reviewed with station specific scale at CSP level. Current process is overlay manual</span>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Charlie Bridges RFS</span></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01976</td><td class="data-plain">Safety Snapshots Report Metrics</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A Product Owners<br><br>
I want<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;"> to see Metrics on the Safety Snapshots Report</span><br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">So that Riley Milligan can see how many users have ran the "Accident and Injury Pie Charts" Report. The report is located in the Safety Department Folder &gt; Safety Performance Measurement &gt; Safety Snapshots Report</span><br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Riley Milligan RFS</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">The ability to see how many users have ran the "Accident and Injury Pie Charts" Report. The report is located in the Safety Department Folder &gt; Safety Performance Measurement &gt; Safety Snapshots Report</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01977</td><td class="data-plain">Add Date Ran to PDF</td><td class="data-plain"></td><td class="data-plain">AAA: Small High Value Business PI19.1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Product Owner<br><br>
I want: To add the date ran to the <span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">vehicle number query (by date) in the Ground/BCSA subfolders</span><br><br>
So that: Shannon Kramer <span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">would like to be able to confirm when this was run and filed.</span><br><br>
Test plan: <br><br>
<span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">Shannon Kramer RFS</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Date ran added to <span style="color: #000000; font-family: 'arial' , 'helvetica' , sans-serif; font-size: small;">vehicle number query (by date) in the Ground/BCSA subfolders</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02072</td><td class="data-plain">Complete App Rationalization Scorecard (Critical Applications) - Due 26Apr2019</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>From:</strong> Pamm Crouse <br> <strong>Sent:</strong> Thursday, March 7, 2019 8:39 AM<br> <strong>To:</strong> IT.GroundSystems.Derrico.AllEmployees &lt;IT.GroundSystems.Derrico.AllEmployees@corp.ds.fedex.com&gt;<br> <strong>Cc:</strong> John Engstrom &lt;john.engstrom@fedex.com&gt;; Christopher Heiting &lt;christopher.heiting@fedex.com&gt;; Anthony James &lt;anthony.james@fedex.com&gt;; Kerri Lindsey &lt;kerri.lindsey@fedex.com&gt;; Krystal Quinn &lt;kquinn@fedex.com&gt;; Joseph King &lt;joseph.a.king@fedex.com&gt;; Scott Leasure &lt;scott.leasure@fedex.com&gt;; Jason Christy &lt;jason.christy@fedex.com&gt;; Brooke Ramachandran &lt;brooke.ramachandran@fedex.com&gt;; Ivan Domacinovich &lt;idomacinovich@fedex.com&gt;; DnA Ops Excellence &lt;DnA_Ops_Excellence@corp.ds.fedex.com&gt;<br> <strong>Subject:</strong> DnA App Rationalization Update<br><br>
 <br><br>
In preparation for PI19.2, we would like to provide additional information to assist you with planning for App Rationalization in the next PI.  As a reminder, the goal of App Rationalization is to determine the disposition of all DnA applications (retire, retain, replace, re-engineer), as well as determine internal alignment of applications within DnA.   In PI19.1, the Ops Excellence team created artifacts to assist in application assessment: <br><br>
 <br><br>

    • App Rationalization Template  <br>
    • App Rationalization Scorecard  <br>

 <br><br>
For PI19.2, we ask that all teams complete the following:  <br><br>
 <br><br>
<table style="width: 100%;" border="1" width="0">
<tbody>
<tr>
<td width="207">
<strong>Action Item </strong> <br><br>
</td>
<td width="308">
<strong>Description </strong> <br><br>
</td>
<td width="114">
<strong>Due Date </strong> <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Scorecard (Critical Applications) <br><br>
</td>
<td width="308">
Work as a team to assess the applications disposition, note important information within question 15 in the scorecard.   <br><br>
</td>
<td width="114">
April 26, 2019  <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Scorecard (Non-Critical Applications) <br><br>
</td>
<td width="308">
Work as a team to assess the applications disposition, note important information within question 15 in the scorecard.   <br><br>
</td>
<td width="114">
End of PI19.2  <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Template   <br><br>
</td>
<td width="308">
For each application complete the App Rationalization Template by copying/pasting any current documentation you have available into the template.  <br><br>
</td>
<td width="114">
End of PI19.2  <br><br>
  <br><br>
  <br><br>
</td>
</tr>
</tbody>
</table>
<strong>     **Managers &amp; Teams will determine critical &amp; non-critical applications</strong> <br><br>
 <br><br>
We encourage each team to complete scorecard assessments together. As we’ve welcomed new team members in PI19.1, please use this exercise as an opportunity to transfer application knowledge.  The Ops Excellence team will consolidate the scorecard results and publish those on the DnA Purple Hub page for all to view. There will be a management and architect review to discuss results. <br><br>
 <br><br>
Please go to the DnA Assets (https://work.purplehub.fedex.com/sites/DnA/SitePages/Assets.aspx) page to update the App Rationalization Template for each application, as well as find the link for the App Rationalization Scorecard. We appreciate all that you’ve done to assist with App Rationalization thus far, please feel free to reach out if you have any questions or need assistance.   <br><br>
 <br><br>
Thank You! <br><br>
DnA Ops Excellence Team <br><br>
 <br><br>
 <br><br>
____________________________________________________ <br><br>
<strong>DnA Operational Excellence</strong><br><br>
DnA_Ops_Excellence@corp.ds.fedex.com (mailto:%3CDnA_Ops_Excellence@corp.ds.fedex.com)  <br><br>
Shatara Washington, Manager<br><br>
Pamm Crouse, Software Developer Advisor<br><br>
Sean Donoghue, Software Developer I<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Critical applications defined<br>
    • Dispositions defined<br>
    • Scorecards completed<br>
</td><td class="data-plain">Jay Varner</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain">B-02090</td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02073</td><td class="data-plain">Complete App Rationalization Scorecard (Non-Critical Applications)</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>From:</strong> Pamm Crouse <br> <strong>Sent:</strong> Thursday, March 7, 2019 8:39 AM<br> <strong>To:</strong> IT.GroundSystems.Derrico.AllEmployees &lt;IT.GroundSystems.Derrico.AllEmployees@corp.ds.fedex.com&gt;<br> <strong>Cc:</strong> John Engstrom &lt;john.engstrom@fedex.com&gt;; Christopher Heiting &lt;christopher.heiting@fedex.com&gt;; Anthony James &lt;anthony.james@fedex.com&gt;; Kerri Lindsey &lt;kerri.lindsey@fedex.com&gt;; Krystal Quinn &lt;kquinn@fedex.com&gt;; Joseph King &lt;joseph.a.king@fedex.com&gt;; Scott Leasure &lt;scott.leasure@fedex.com&gt;; Jason Christy &lt;jason.christy@fedex.com&gt;; Brooke Ramachandran &lt;brooke.ramachandran@fedex.com&gt;; Ivan Domacinovich &lt;idomacinovich@fedex.com&gt;; DnA Ops Excellence &lt;DnA_Ops_Excellence@corp.ds.fedex.com&gt;<br> <strong>Subject:</strong> DnA App Rationalization Update<br><br>
 <br><br>
In preparation for PI19.2, we would like to provide additional information to assist you with planning for App Rationalization in the next PI.  As a reminder, the goal of App Rationalization is to determine the disposition of all DnA applications (retire, retain, replace, re-engineer), as well as determine internal alignment of applications within DnA.   In PI19.1, the Ops Excellence team created artifacts to assist in application assessment: <br><br>
 <br><br>

    • App Rationalization Template  <br>
    • App Rationalization Scorecard  <br>

 <br><br>
For PI19.2, we ask that all teams complete the following:  <br><br>
 <br><br>
<table style="width: 100%;" border="1" width="0">
<tbody>
<tr>
<td width="207">
<strong>Action Item </strong> <br><br>
</td>
<td width="308">
<strong>Description </strong> <br><br>
</td>
<td width="114">
<strong>Due Date </strong> <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Scorecard (Critical Applications) <br><br>
</td>
<td width="308">
Work as a team to assess the applications disposition, note important information within question 15 in the scorecard.   <br><br>
</td>
<td width="114">
April 26, 2019  <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Scorecard (Non-Critical Applications) <br><br>
</td>
<td width="308">
Work as a team to assess the applications disposition, note important information within question 15 in the scorecard.   <br><br>
</td>
<td width="114">
End of PI19.2  <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Template   <br><br>
</td>
<td width="308">
For each application complete the App Rationalization Template by copying/pasting any current documentation you have available into the template.  <br><br>
</td>
<td width="114">
End of PI19.2  <br><br>
  <br><br>
  <br><br>
</td>
</tr>
</tbody>
</table>
<strong>     **Managers &amp; Teams will determine critical &amp; non-critical applications</strong> <br><br>
 <br><br>
We encourage each team to complete scorecard assessments together. As we’ve welcomed new team members in PI19.1, please use this exercise as an opportunity to transfer application knowledge.  The Ops Excellence team will consolidate the scorecard results and publish those on the DnA Purple Hub page for all to view. There will be a management and architect review to discuss results. <br><br>
 <br><br>
Please go to the DnA Assets (https://work.purplehub.fedex.com/sites/DnA/SitePages/Assets.aspx) page to update the App Rationalization Template for each application, as well as find the link for the App Rationalization Scorecard. We appreciate all that you’ve done to assist with App Rationalization thus far, please feel free to reach out if you have any questions or need assistance.   <br><br>
 <br><br>
Thank You! <br><br>
DnA Ops Excellence Team <br><br>
 <br><br>
 <br><br>
____________________________________________________ <br><br>
<strong>DnA Operational Excellence</strong><br><br>
DnA_Ops_Excellence@corp.ds.fedex.com (mailto:%3CDnA_Ops_Excellence@corp.ds.fedex.com)  <br><br>
Shatara Washington, Manager<br><br>
Pamm Crouse, Software Developer Advisor<br><br>
Sean Donoghue, Software Developer I<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Non-critical applications defined<br>
    • Dispositions defined<br>
    • Scorecards completed<br>
</td><td class="data-plain">Jay Varner</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02074</td><td class="data-plain">Complete App Rationalization Template</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>From:</strong> Pamm Crouse <br> <strong>Sent:</strong> Thursday, March 7, 2019 8:39 AM<br> <strong>To:</strong> IT.GroundSystems.Derrico.AllEmployees &lt;IT.GroundSystems.Derrico.AllEmployees@corp.ds.fedex.com&gt;<br> <strong>Cc:</strong> John Engstrom &lt;john.engstrom@fedex.com&gt;; Christopher Heiting &lt;christopher.heiting@fedex.com&gt;; Anthony James &lt;anthony.james@fedex.com&gt;; Kerri Lindsey &lt;kerri.lindsey@fedex.com&gt;; Krystal Quinn &lt;kquinn@fedex.com&gt;; Joseph King &lt;joseph.a.king@fedex.com&gt;; Scott Leasure &lt;scott.leasure@fedex.com&gt;; Jason Christy &lt;jason.christy@fedex.com&gt;; Brooke Ramachandran &lt;brooke.ramachandran@fedex.com&gt;; Ivan Domacinovich &lt;idomacinovich@fedex.com&gt;; DnA Ops Excellence &lt;DnA_Ops_Excellence@corp.ds.fedex.com&gt;<br> <strong>Subject:</strong> DnA App Rationalization Update<br><br>
 <br><br>
In preparation for PI19.2, we would like to provide additional information to assist you with planning for App Rationalization in the next PI.  As a reminder, the goal of App Rationalization is to determine the disposition of all DnA applications (retire, retain, replace, re-engineer), as well as determine internal alignment of applications within DnA.   In PI19.1, the Ops Excellence team created artifacts to assist in application assessment: <br><br>
 <br><br>

    • App Rationalization Template  <br>
    • App Rationalization Scorecard  <br>

 <br><br>
For PI19.2, we ask that all teams complete the following:  <br><br>
 <br><br>
<table style="width: 100%;" border="1" width="0">
<tbody>
<tr>
<td width="207">
<strong>Action Item </strong> <br><br>
</td>
<td width="308">
<strong>Description </strong> <br><br>
</td>
<td width="114">
<strong>Due Date </strong> <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Scorecard (Critical Applications) <br><br>
</td>
<td width="308">
Work as a team to assess the applications disposition, note important information within question 15 in the scorecard.   <br><br>
</td>
<td width="114">
April 26, 2019  <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Scorecard (Non-Critical Applications) <br><br>
</td>
<td width="308">
Work as a team to assess the applications disposition, note important information within question 15 in the scorecard.   <br><br>
</td>
<td width="114">
End of PI19.2  <br><br>
</td>
</tr>
<tr>
<td width="207">
Complete App Rationalization Template   <br><br>
</td>
<td width="308">
For each application complete the App Rationalization Template by copying/pasting any current documentation you have available into the template.  <br><br>
</td>
<td width="114">
End of PI19.2  <br><br>
  <br><br>
  <br><br>
</td>
</tr>
</tbody>
</table>
<strong>     **Managers &amp; Teams will determine critical &amp; non-critical applications</strong> <br><br>
 <br><br>
We encourage each team to complete scorecard assessments together. As we’ve welcomed new team members in PI19.1, please use this exercise as an opportunity to transfer application knowledge.  The Ops Excellence team will consolidate the scorecard results and publish those on the DnA Purple Hub page for all to view. There will be a management and architect review to discuss results. <br><br>
 <br><br>
Please go to the DnA Assets (https://work.purplehub.fedex.com/sites/DnA/SitePages/Assets.aspx) page to update the App Rationalization Template for each application, as well as find the link for the App Rationalization Scorecard. We appreciate all that you’ve done to assist with App Rationalization thus far, please feel free to reach out if you have any questions or need assistance.   <br><br>
 <br><br>
Thank You! <br><br>
DnA Ops Excellence Team <br><br>
 <br><br>
 <br><br>
____________________________________________________ <br><br>
<strong>DnA Operational Excellence</strong><br><br>
DnA_Ops_Excellence@corp.ds.fedex.com (mailto:%3CDnA_Ops_Excellence@corp.ds.fedex.com)  <br><br>
Shatara Washington, Manager<br><br>
Pamm Crouse, Software Developer Advisor<br><br>
Sean Donoghue, Software Developer I<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Template completed<br>
</td><td class="data-plain">Jay Varner</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02085</td><td class="data-plain">PSSC: App Rationalization: Complete Score Card Assessment for FTRACK</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to complete the scorecard assessment for FTRACK so that we can determine the disposition of this application in reference to the Four R's.<br><br>
Note: Critical Application<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Scorecard must be complete by April 26, 2019<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02086</td><td class="data-plain">PSSC: App Rationalization: Complete the scorecard assessment for HOS/Station</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to complete the scorecard assessment for HOS/Station so that we can determine the disposition of this application in reference to the Four R's.<br> <br>Note: Critical Application<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Scorecard must be complete by April 26, 2019<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02087</td><td class="data-plain">PSSC: App Rationalization: complete the scorecard assessment for Service Measurement</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to complete the scorecard assessment for Service Measurement so that we can determine the disposition of this application in reference to the Four R's.<br><br>
Note: Critical Application<br><br><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Scorecard must be complete by April 26, 2019<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02088</td><td class="data-plain">PSSC: App Rationalization: Spike: Define ideal application state</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">SPIKE:  As an Ops Excellence Team, we want to define the ideal state of an application, so that we know what criteria should be included in the Gap Analysis Matrix.<br><br>
Notes: <br>Discuss with PSSC team their thoughts on ideal state<br>This is an on-going process and ideal state is always changing. Ideal state should adhere to most current architectural and design standards.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Excel doc defining criteria of ideal state of app<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02089</td><td class="data-plain">PSSC: App Rationalization: Complete the scorecard assessment for MPS Reporting</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to complete the scorecard assessment for MPS Reporting so that we can determine the disposition of this application in reference to the Four R's.<br><br>
Note: Non-Critical Application<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Scorecard must be complete by end of PI19.2<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02090</td><td class="data-plain">PSSC: App Rationalization: Consolidate the scorecard assessments for critical applications</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As the Ops Excellence Team, we want to consolidate the scorecard assessments for critical applications so that we can summarize the results.<br><br>
NOTE:  Critical Applications are determined by the DnA team that currently supports the applications.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">B-02072</td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02091</td><td class="data-plain">PSSC: App Rationalization: Consolidate the scorecard assessments for non-critical applications</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As the Ops Excellence Team, we want to consolidate the scorecard assessments for non-critical applications so that we can summarize the results.<br><br>
NOTE:  Non-Critical Applications are determined by the DnA team that currently supports the applications.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02092</td><td class="data-plain">PSSC: App Rationalization: Develop matrix that enables completion of DnA Gap Analysis</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to create the Gap Analysis Matrix, based on the established ideal state criteria, so that we can perform the gap analysis on all DnA applications.<br><br>
<br>Dependency: Determine the list of all current DnA applications<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Excel doc defining ideal state criteria vs DnA applications<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02093</td><td class="data-plain">PSSC: App Rationalization: Determine top 3 list of Gaps Identified with all DnA apps</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to perform the gap analysis on all applications within DnA so that we can identify any gaps.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Define a list of all gaps identified<br>Prioritize top three gaps based on Ops Excellence Roadmap<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02094</td><td class="data-plain">PSSC: App Rationalization: Define a strategy to implement possible process improvements/standard</td><td class="data-plain"></td><td class="data-plain">App rationalization</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to define a strategy to implement possible process improvements/standards so that we can eliminate identified gaps.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02007</td><td class="data-plain">Create Schema based on Public Data</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a dummy schema that contains the acceptance criteria below based on a public data set.<br><br>
<span style="color: #000000; font-family: 'Times New Roman'; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;"> </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Event data with a timestamp<br>
    • A cluster key<br>
    • Has a field that can be aggregated on<br>
    • At least one field has a non-ideal name that will need to be changed in BigQuery storage<br>
    • Partition by timestamp<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02009</td><td class="data-plain">Create BigQuery Table</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a big query table off of the schema created previously. This is a backup story if creating the table based off a schema is too complex<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Table is created<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02011</td><td class="data-plain">Op Excellence – Metrics</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a custom metric that Stackdriver can monitor<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Stackdriver monitoring a method or step in the dataflow<br>
    • Ideally: Through the API<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02013</td><td class="data-plain">Op Excellence – Dashboard</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a dashboard for the Dataflow jobs so that I can monitor the applications<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • A dashboard that contains KPI of the pipeline<br>
    • Includes a custom metric<br>
    • Ideally: Through the API<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02014</td><td class="data-plain">Op Excellence – Alert</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create an alert when the application goes outside of the standard KPI<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • An alert sent to the team (could be as simple as an email)<br>
    • Ideally: Through the API<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02015</td><td class="data-plain">Update Strategy whitepapers</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to write / update any whitepapers based on the lessons learned.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Make it more of a what we are doing versus here is what is out there

        • Outline the strategy<br>

<br>
    • Create Strategy documents based on Op Excellence items<br>
    • Any of the other documents<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02054</td><td class="data-plain">Nice to Have: How to Handle the failure? Aka bad schema or invalid data type</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to develop a strategy on how to handle bad messages and implement in the simple pipeline<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Strategy and options are documented<br>
    • First filter out bad data<br>
    • Implemented a chosen strategy for the simple pipeline<br>
    • Number of failed records included in the metadata<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02055</td><td class="data-plain">Nice to Have: More fields? – Schema Evolutions</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I wanted to determine how to handle if a feed has more fields then we are storing, especially if it’s in addition to the schema<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Strategy and options are documented<br>
    • Implemented a chosen strategy for the simple pipeline<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02056</td><td class="data-plain">Nice to Have: 500 column BigQuery table?</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to see how BigQuery handles a large number of columns such as 500 fields.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Create a table with data with a large number of columns to see how big query handles it<br>
    • With nested columns<br>
    • Results are documented<br>
    • Does not require a full pipeline<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02059</td><td class="data-plain">Nice to Have: Look up</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to do a look up to another service /data set in the simple pipeline<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Do a join (create a new bigquery table)<br>
    • Call a web service<br>
    • Add metrics for calling the web service<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02063</td><td class="data-plain">Nice to Have: Template Dashboards / Metrics / etc…</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I wanted to create a template for the common KPI and metrics for all data flow jobs that be instantiated quickly<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Template base to create the common KPI and metrics<br>
    • Ability to configure and run to create the templates<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02064</td><td class="data-plain">Nice to Have: Security</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to obfuscate and mask a column to securely store data.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Using a pipeline obfuscate a column<br>
    • Using a pipeline mask a column<br>
    • Update the obfuscation strategy if necessary<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02065</td><td class="data-plain">SPIKE: Training</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount">40.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I need to know fundamentals of Java , GIT , Maven and GCP components. I will be training on these.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Training for GCP/Foundational Items<br><br></td><td class="data-plain">Yogesh Sharma,Larry Barbian,Rahul Akurathi,Hemant Lingayat (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount">240.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">240.00</td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02201</td><td class="data-plain">Roadmap</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer I want to update the Roadmap<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">An updated Roadmap is published and share with the Architects, Deep, and Tim.<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02213</td><td class="data-plain">SPIKE: Talk with Google</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to pick Google’s brain on how they handle common components, orchestration, and dynamic configuration of jobs.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Documented notes and update strategy white papers<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02214</td><td class="data-plain">Spike: Cloud Composer</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to investigate and understand Cloud Composer (Airflow) so that I can understand if it applicable for orchestration of integration pipelines.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Research completed with notes documented<br>
    • Create standards and/or strategy whitepaper<br>
    • Share knowledge with ingestion team<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02215</td><td class="data-plain">Spike: How do we pass parameters</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to determine the best way to pass parameters for the components themselves as well as bootstrap configuration for the components.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Updated documentation and standards of how to handle configuration of components<br>
    • Updated documentation and standards of how to handle bootstrap configuration of components<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02216</td><td class="data-plain">Spike: Define Component Lifecycle</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a component lifecycle as to define the steps of a common component. This will help create the standard metadata, hook in for configuration, and reusability of the components.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Life Cycle created<br>
    • Documented and include in the standards<br>
    • Metadata collected by default in the lifecycle<br>
    • How configuration can be loaded as part of the Component lifecycle<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02217</td><td class="data-plain">Create barebones Pipeline</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a job that will pull from big query and store them in big query with minimal common re-use. Treat more as a learning experience.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Partition based on the event timestamp (and in the correct format – local and utc)<br>
    • Use an id for a cluster key<br>
    • Message is cleanse based on the schema and allowed values<br>
    • Stored in big query based on the schema and correct map columns.<br>
    • A service account is used to run the application<br>
    • Bad records or any failures are ignored<br>
    • Metadata

        • The pipeline will include the start and end time of the batch processing as well as the number of records processed (confirm Stackdriver)<br>

<br>
    • Code is unit tested

        • Every Function<br>
        • Entire Pipeline<br>

<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02218</td><td class="data-plain">CI/CD</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to use a CI/CD pipeline to deploy the barebones pipelines.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Barebones pipeline is deployed to GCP with a service account with a Jenkins Pipeline<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02219</td><td class="data-plain">Create Metadata Plug-in</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create the metadata plug-in to be applied to a component so that way I can include the common metadata collection that would be expected.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Metadata plug-in is created and unit tested.<br>
    • This fits in the component lifecycle<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02220</td><td class="data-plain">Create the Parameter Plug-in</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to create a parameter plug-in for the common component so that I can load up a component with configuration.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Allow a component to load standard configuration from a source e.g. BigQuery<br>
    • Use a Custom Pipeline Parameter to load whatever configuration is need to hit a source<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02221</td><td class="data-plain">Create data pipeline - Common</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to update the data pipeline to include the common components<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • The component lifecycle is implemented<br>
    • The meta-plug in is used in all major components<br>
    • The parameter plug-in is used in all major components<br>
    • All abstractions are completed as necessary<br>
    • Use cloud composer to run it<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02222</td><td class="data-plain">SPIKE: Discuss and Define Standards with ISMP</td><td class="data-plain"></td><td class="data-plain">BPR - Integration Framework MVP</td><td class="data-plain">Ready</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">I want to talk with ISMP team to define standards.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • package naming structure<br>
    • code starter/archtype<br>
    • unit testing<br>
    • builder pattern for transforms<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02066</td><td class="data-plain">Automated E-4/E-5 Clean up</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">BPR - KLO</td><td class="data-plain">Ready</td><td class="data-amount">7.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to automate the fix for cleaning E-4/E-5 folders.<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">If there is any data in the bad partition in Hadoop, it will be automatically moved to correct location and the bad folders will be deleted.<br><br></td><td class="data-plain">Yogesh Sharma</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount">53.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">53.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Intangible</td><td class="data-plain">B-02067</td><td class="data-plain">PLP synch-up Deployment</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">BPR - KLO</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Clean up after initial PLP Ab Initio production deployment:<br><br>
Synchronize production Ab Initio PLP code with development repository. <br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Ab Initio PLP development repository is up-to-date and and that has been deployed to production.<br><br>
Results from PLP Monthly run before synchronization and deploy match the results from after.<br><br></td><td class="data-plain">Larry Barbian</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount">44.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">44.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02068</td><td class="data-plain">Remove obsolete Teradata structure</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">BPR - KLO</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to remove all the obsolete tables from Teradata.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">All the obsolete table are dropped<br><br></td><td class="data-plain">Yogesh Sharma</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount">14.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">14.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02069</td><td class="data-plain">DSA Zero-byte files</td><td class="data-plain"></td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I want to automate the process to clean up log, error and other zero byte files in the Abinitio directory for DSA application.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">All Zero byte files older than 2 days are automatically purged<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02070</td><td class="data-plain">Retire Critical Entry Time App</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount">5.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">5.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02071</td><td class="data-plain">Retirement of HDPSN Workflow</td><td class="data-plain"></td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount">8.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">8.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02133</td><td class="data-plain">Unplanned Work - Iteration 1 2019 - BPR</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02135</td><td class="data-plain">Unplanned Work - Iteration 3 2019 - BPR</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02136</td><td class="data-plain">Unplanned Work - Iteration 4 2019 - BPR</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Fixed Date</td><td class="data-plain">B-02202</td><td class="data-plain">OSMP Protect Purple Upgrades</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">BPR - KLO</td><td class="data-plain">In Progress</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As Business User, I want OSMP to be compliant with the security requirements so that I am able to upload the 5 files to maintain services standards.<br><br>
 <br><br>
Comments: It is unknown how much work will truly be needed because it is an old application and it may break other dependencies that we are not aware of.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Spring 3.x or higher (do not upgrade to Spring Boot)<br><br>
Java 8 compatible<br><br>
The 5 services standard files can still be uploaded (see attached email)<br><br>
Code coverage is maintained<br><br></td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount">25.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">25.00</td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01246</td><td class="data-plain">Unplanned - Decommission HDPSN workflow - Part I</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">BPR - KLO</td><td class="data-plain">In Progress</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">The GSI Dashboard is no longer used (See attached).  The purpose of this story is to reconfigure the One Automation jobs to run the required jobs, but disable the jobs that is specific for creating the GSI Dashboard. 
  
Acceptance Criteria 
1. HDDAY runs on an indepdent schedule 
2. The teradata feeds for lmda_arrival, pobox, and holidays are done on an independent daily On Automation Job 
3. DeliveryPostageDetailsMain job based on the first line of delivery_optimization_charts_sequence.config runs once daily in One Automation 
4. The HDPSN workflow is disabled.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Brad Semrad</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">47.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">38.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01746</td><td class="data-plain">Unplanned - Decommission HDPSN workflow - Part II</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">The GSI Dashboard is no longer used (See attached).  The purpose of this story is to clean up unused code for the GSI Dashboard. 
  
Acceptance Criteria 
1. The following One Automation jobs/workflows are eliminated: 
 
HDPSN 
HDPDO 
HDPFS.P2 
HDPAP 
 
2. Delete Oracle Tables - See Task 
3. Delete One Automation Scripts - See Task 
4. Delete GSI Dashboard - See Task 
5. Delete spark jobs - See Task 
6. Delete Hive tables - See Task</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">30.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">30.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02134</td><td class="data-plain">Unplanned Work - Iteration 2 2019 - BPR</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">BPR - KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01856</td><td class="data-plain">PSSC: Stack Driver - System Level Logging</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Create a strategy for implementing stack driver logging for GCP environment. 
We should be able to, 
- implement logging for native google apps and services and resources 
- Give guidance on how to consume a stack driver log</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01857</td><td class="data-plain">PSSC: Stack Driver - Trace Level Logging</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Create a strategy for implementing stack driver - Trace Level logging for GCP environment. 
We should be able to, 
- implement logging for native google apps and services and resources 
- Give guidance on how to consume a stack driver log</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01858</td><td class="data-plain">PSSC: Stack Driver - Monitoring Console</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">We should be able to, 
- understand how to build custom dashboard through the monitoring tool 
- how to consume the prebuild Google Templates</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01859</td><td class="data-plain">PSSC: Stack Driver - Notifications and Alerting</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">We should create a strategy for 
- Implement monitoring and Alerts in GCP 
- Implement integration with PDSM</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01888</td><td class="data-plain">PSSC: Platform 1.0: Define the necessary resources for the Google MVP Project</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Define the Google Project <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01889</td><td class="data-plain">PSSC: Platform 1.0 :Allocate / Create resources for the project</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Allocate / Create resources for the project using Terraform.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01890</td><td class="data-plain">PSSC: Platform 1.0: Provide access to Google Cloud for DnA team members</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Provide secure access to project via AD groups <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01892</td><td class="data-plain">PSSC: Spike: Platform 1.0: Initial architecture discussion - foldering / labeling etc.</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">For Cloud Administration, discuss with architects the plan for foldering /labeling etc. <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Defined and Accepted foldering strategy<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01893</td><td class="data-plain">PSSC: Spike: Platform 1.0: In-depth planning with larger architect/tech lead discussion to understand gaps</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Need a detailed planning meeting with extended architects / tech leads to discuss and understand gaps and plan in-depth, the details of cloud administration<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01894</td><td class="data-plain">PSSC: Platform 1.0: Review and Publish for finance / chargebacks for consumption</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Review and Publish for finance / charge-backs for consumption</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01906</td><td class="data-plain">PSSC: Stackdriver Alerting &amp; Monitoring: Stack Driver - System Level Logging</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Create a strategy for implementing stack driver logging for GCP environment. </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>We should be able to, </span><br><br>
<span>- implement logging for native google apps and services and resources </span><br><br>
<span>- Give guidance on how to consume a stack driver log</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01907</td><td class="data-plain">PSSC: Stackdriver Alerting &amp; Monitoring: Stack Driver - Trace Level Logging</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Create a strategy for implementing stack driver trace level logging for GCP environment. </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>We should be able to, </span><br><br>
<span>- implement logging for native google apps and services and resources </span><br><br>
<span>- Give guidance on how to consume a stack driver log</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01909</td><td class="data-plain">PSSC: Stackdriver Alerting &amp; Monitoring: Stack Driver Monitoring Control</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>We should be able to, </span><br><br>
<span>- understand how to build custom dashboard through the monitoring tool</span><br><br>
<span> - how to consume the prebuild Google Templates</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01910</td><td class="data-plain">PSSC: Stack Driver - Notifications and Alerting</td><td class="data-plain"></td><td class="data-plain">Cloud Infrastructure 1.0</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>We should create a strategy for </span><br><br>
<span>- Implement monitoring and Alerts in GCP </span><br><br>
<span>- Implement integration with PDSM</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01317</td><td class="data-plain">Consume FXGSHIP.FXG.MVE.DIMS Topic</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.DIMS Topic</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As an analyst 
I want the above topic consumed 
So that we can create confidence metrics around equipment and measurements for the application of operational exemptions and epdi approvals 
  
Acceptance Criteria: 
All Dims stored in big data analytic environment 
Need equipment ids stored with all dim changes (scanner, employee, sorter, etc)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01323</td><td class="data-plain">One Automation Job to kick off spark job</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01324</td><td class="data-plain">Spark Job</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">1.
Read all the files in the staging directory
 
2.
Parse the files
 
3.
Partition By Event Dt
 
4.
Store Hive ORC partition files
 
5.
Delete the processed files
 
6.
Delete .staging files</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01806</td><td class="data-plain">Ab Initio - Batch Job</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">1. Read Ab
 Initio Queue
 
2. Create zip file
 
3. Write flat file to hdfs staging directory</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01807</td><td class="data-plain">Ab Initio Continuous jobs: Jms queue to Abinitio Queue(Local disk)</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">11.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">1. Read JMS queue message 
2. Call upn web service and add to message 
 
3. Store
 on Ab Initio Queue</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01808</td><td class="data-plain">Create Hive Table in FXG_DB</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01809</td><td class="data-plain">Create JMS Queue - PROD</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Need to create the prod queue by creating a PDSM catalog task to the team: FXS_SystemTeamGSI.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01810</td><td class="data-plain">Create JMS Queues - L0 to L4</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SORT topic</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Created the following PDSM request: 
  
Order Placed: 
2018-09-07 14:52:32   
 
Request Number:  
REQ1048469    
  
 
Estimated Delivery Date of Complete Order:   
2018-09-07</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01569</td><td class="data-plain">Store Data From FXGSHIP.FXG.MVE.SWAK topic</td><td class="data-plain"></td><td class="data-plain">Consume FXGSHIP.FXG.MVE.SWAK Topic</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As an analyst 
I want the above topic consumed 
So that we can create confidence metrics around package metrics and SWAK Scans 
  
Acceptance Criteria: 
All Dims stored in big data analytic environment 
Need equipment ids stored with all dim changes (scanner, employee, sorter, etc)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01792</td><td class="data-plain">Add UPN (Spike)</td><td class="data-plain"></td><td class="data-plain">Create Ingestion Pipeline: Ingest streaming pickup and delivery scans from JMS topic: FXGSHIP.FXG.OPS.STOP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01793</td><td class="data-plain">Bring Google In (Spike)</td><td class="data-plain"></td><td class="data-plain">Create Ingestion Pipeline: Ingest streaming pickup and delivery scans from JMS topic: FXGSHIP.FXG.OPS.STOP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01794</td><td class="data-plain">Consumer Build/Config</td><td class="data-plain"></td><td class="data-plain">Create Ingestion Pipeline: Ingest streaming pickup and delivery scans from JMS topic: FXGSHIP.FXG.OPS.STOP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01795</td><td class="data-plain">Performance Testing</td><td class="data-plain"></td><td class="data-plain">Create Ingestion Pipeline: Ingest streaming pickup and delivery scans from JMS topic: FXGSHIP.FXG.OPS.STOP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Outbound faster than inbound</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01796</td><td class="data-plain">Request Queue(s)</td><td class="data-plain"></td><td class="data-plain">Create Ingestion Pipeline: Ingest streaming pickup and delivery scans from JMS topic: FXGSHIP.FXG.OPS.STOP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01797</td><td class="data-plain">Target App build/config</td><td class="data-plain"></td><td class="data-plain">Create Ingestion Pipeline: Ingest streaming pickup and delivery scans from JMS topic: FXGSHIP.FXG.OPS.STOP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02113</td><td class="data-plain">Customer Churn</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Customer Churn</td><td class="data-plain">In Progress</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Evaluate existing Customer Churn modeling and design so that future design potentials are relevant and scoped for ongoing development<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Brandon Walker</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02114</td><td class="data-plain">Customer Zip-7 Density 1 of 3</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Customer Zip-7 Density</td><td class="data-plain">In Progress</td><td class="data-amount">4.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage Finance to determine scope needs around evaluating and measuring customers zip-7 density performance, so that opportunities can be developed for Finance to take action to improve density and thereby settlement savings<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Brandon Walker</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02223</td><td class="data-plain">Customer Zip-7 Density  2 of 3</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Customer Zip-7 Density</td><td class="data-plain">Ready</td><td class="data-amount">4.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage Finance to determine scope needs around evaluating and measuring customers zip-7 density performance, so that opportunities can be developed for Finance to take action to improve density and thereby settlement savings<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Brandon Walker</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02224</td><td class="data-plain">Customer Zip-7 Density 3 of 3</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Customer Zip-7 Density</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage Finance to determine scope needs around evaluating and measuring customers zip-7 density performance, so that opportunities can be developed for Finance to take action to improve density and thereby settlement savings<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Angela Kao</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01978</td><td class="data-plain">Training for Datalab and Cloud ML</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist and developer, I need to know Datalab and Cloud ML, so that I may build an analytical model and deploy it for business analytics.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Setup Google SDK<br>
    • Know auto-scaling features<br>
    • Know Datalab sizes<br>
    • Know data permissions<br>
    • Know project permissions<br>
</td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01979</td><td class="data-plain">Find an existing data model</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I need a data model, so that it can be deployed and predictions can be made.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01980</td><td class="data-plain">Import data for ML model</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist, I need data, so that it can be used by an ML model.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Data is accessible in GCP<br><br></td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01981</td><td class="data-plain">Layout project in GCP</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I need to work with the architects to determine a project layout, so that an enterprise standard is utilized. <br><br>Note: work with Paper Street Soap Company (Eric)<br><br><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Project folders are setup in GC Storage<br><br></td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01982</td><td class="data-plain">Create Datalab instance(s) in GCP</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 3</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">[image https://www19.v1host.com/FedEx/downloadblob.img/751C0D7DD5C280840CD80B788BDBEC8C91AA8CFC] As a data scientist, I want to create a Datalab instance so that I have a development environment.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Connect to project bucket<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01983</td><td class="data-plain">Connect Datalab to Gitlab repo</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist and developer, I need to connect to a Gitlab repository from Datalab, so that I can save my models and notebooks.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Connect a Datalab instance to a Gitlab repo<br>
    • Commit a notebook to a Gitlab repo<br>
</td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01984</td><td class="data-plain">Deploy machine learning model on Cloud ML</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist, I need to be able to deploy a model on Cloud ML, so that it can provide business value.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    • Model is deployed on Cloud ML<br>
    • Model can be called via REST, and give back predictions<br>
    • Deploy through a Jenkins pipeline<br>
</td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01985</td><td class="data-plain">SPIKE: Error logging for deployed models</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I need logging, so that I know if there are any issues with a deployed model and be able to trace those issues.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01986</td><td class="data-plain">SPIKE: Notifications for deployed models</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer and data scientist, I need notifications/alerting, so that I know if there is something critical with a deployed model<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01987</td><td class="data-plain">SPIKE: Monitoring model performance deployed on Cloud ML</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I need to be able to monitor errors and resources for a deployed model, so that I can proved support.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01988</td><td class="data-plain">SPIKE: Monitoring model accuracy deployed on Cloud ML</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist, I need to know the accuracy of a deployed model, so that I know if the model needs to be tuned.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01989</td><td class="data-plain">Train data model through Cloud ML</td><td class="data-plain"></td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist, I need to be able to train models through Cloud ML, so that the training can be scalable, and distributed.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01990</td><td class="data-plain">Clean data with Dataprep</td><td class="data-plain"></td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist, I want to be able to transform data through Dataprep, so that it is self-serving, and a repeatable process.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01991</td><td class="data-plain">Create a PyTorch model in Datalab</td><td class="data-plain"></td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As data scientist, I need to be able to use PyTorch in Datalab, so that I can take advantage of the latest technologies.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01992</td><td class="data-plain">Deploy a PyTorch model in GCP</td><td class="data-plain"></td><td class="data-plain">Data Science Tooling MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer, I need to be able to deploy a PyTorch model in GCP, so that it can be scalable and distributed.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02115</td><td class="data-plain">Delivery Optimization Evolution 1 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Delivery Optimization Evolution</td><td class="data-plain">In Progress</td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support Delivery Optimization Evolution through daily maintenance, Blackjack support, and evolving use of capabilities so that package delivery methods have the opportunity to meet/exceed Plan forecasts/Strategic goals<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Angela Kao</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02225</td><td class="data-plain">Delivery Optimization Evolution 2 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Delivery Optimization Evolution</td><td class="data-plain">Ready</td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support Delivery Optimization Evolution through daily maintenance, Blackjack support, and evolving use of capabilities so that package delivery methods have the opportunity to meet/exceed Plan forecasts/Strategic goals<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Kimberly Jane Rice</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02226</td><td class="data-plain">Delivery Optimization Evolution 3 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Delivery Optimization Evolution</td><td class="data-plain">Ready</td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support Delivery Optimization Evolution through daily maintenance, Blackjack support, and evolving use of capabilities so that package delivery methods have the opportunity to meet/exceed Plan forecasts/Strategic goals<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Clayton Clouse</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02227</td><td class="data-plain">Delivery Optimization Evolution 4 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Delivery Optimization Evolution</td><td class="data-plain">Ready</td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support Delivery Optimization Evolution through daily maintenance, Blackjack support, and evolving use of capabilities so that package delivery methods have the opportunity to meet/exceed Plan forecasts/Strategic goals<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Joshua Anderson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02228</td><td class="data-plain">Delivery Optimization Evolution 5 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 5</td><td class="data-plain">Delivery Optimization Evolution</td><td class="data-plain">Ready</td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support Delivery Optimization Evolution through daily maintenance, Blackjack support, and evolving use of capabilities so that package delivery methods have the opportunity to meet/exceed Plan forecasts/Strategic goals<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Joshua Anderson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01964</td><td class="data-plain">Design REST Interface</td><td class="data-plain"></td><td class="data-plain">DIIaaS Strategy</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a client,<br><br>
I want the ability to call a REST API that will retrieve data from the analytics engine,<br><br>
So that I can use the results in an operational system.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate the REST API follows REST Best Practices<br>
    • Validate the REST API has been socialized and agreed in its design with the architects<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>: Architects<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01965</td><td class="data-plain">Implement REST Interface and Deploy to PCF Dev</td><td class="data-plain"></td><td class="data-plain">DIIaaS Strategy</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Build out the REST interface and deploy it to DEV PCF<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate the REST API is accessible in PCF<br>
    • Validate the REST API can query Big Query Lab<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>: Architects<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01966</td><td class="data-plain">Create DIIaaS Whitepaper 1.0</td><td class="data-plain"></td><td class="data-plain">DIIaaS Strategy</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Show the strategy and tentative architecture of the DIIaaS Framework.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate Technology Architecture Diagram and notes are shown<br>
    • Validate System Context Integration Logic is shown<br>
    • Validate an Information Architecture (Data and Functional) is shown<br>
    • Validate a roadmap is shown<br>
    • Validate Strategy aligns with MVP Roadmap<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>: Architects<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02116</td><td class="data-plain">Direct Assignment to other value streams 1 of 5</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 1</td><td class="data-plain">Direct Assignment to other value streams</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support eight Value Streams with assigned Data Scientist(s) so that Value Streams can identify future Data Science needs when planning Value Stream work<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Clayton Clouse</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02232</td><td class="data-plain">Direct Assignment to other value streams 2 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Direct Assignment to other value streams</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support eight Value Streams with assigned Data Scientist(s) so that Value Streams can identify future Data Science needs when planning Value Stream work<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Joshua Anderson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02233</td><td class="data-plain">Direct Assignment to other value streams 3 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Direct Assignment to other value streams</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support eight Value Streams with assigned Data Scientist(s) so that Value Streams can identify future Data Science needs when planning Value Stream work<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Erika Lynn Paulson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02234</td><td class="data-plain">Direct Assignment to other value streams 4 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Direct Assignment to other value streams</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support eight Value Streams with assigned Data Scientist(s) so that Value Streams can identify future Data Science needs when planning Value Stream work<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Nathan Cybak</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02235</td><td class="data-plain">Direct Assignment to other value streams 5 of 5</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 5</td><td class="data-plain">Direct Assignment to other value streams</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support eight Value Streams with assigned Data Scientist(s) so that Value Streams can identify future Data Science needs when planning Value Stream work<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Tony Scaldaferri</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02117</td><td class="data-plain">Early Package Visibility (MOON Project #60) 1 of 4</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Early Package Visibility (MOON Project #60)</td><td class="data-plain">In Progress</td><td class="data-amount">100.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Identify/Ingest data sources and scope conceptual model/sub-model design of package to trailer predictions so that Early Package Visibility deliverables are met<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Erika Lynn Paulson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02237</td><td class="data-plain">Early Package Visibility (MOON Project #60) 2 of 4</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 2</td><td class="data-plain">Early Package Visibility (MOON Project #60)</td><td class="data-plain"></td><td class="data-amount">25.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Identify/Ingest data sources and scope conceptual model/sub-model design of package to trailer predictions so that Early Package Visibility deliverables are met<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Clayton Clouse</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02238</td><td class="data-plain">Early Package Visibility (MOON Project #60) 4 of 4</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Early Package Visibility (MOON Project #60)</td><td class="data-plain"></td><td class="data-amount">25.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Identify/Ingest data sources and scope conceptual model/sub-model design of package to trailer predictions so that Early Package Visibility deliverables are met<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Divya Virender Kumar</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02239</td><td class="data-plain">Early Package Visibility (MOON Project #60) 3 of 4</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">Early Package Visibility (MOON Project #60)</td><td class="data-plain"></td><td class="data-amount">25.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Identify/Ingest data sources and scope conceptual model/sub-model design of package to trailer predictions so that Early Package Visibility deliverables are met<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Nathan Cybak</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">D-01001</td><td class="data-plain">Update / Fix db2_cut_tm in Smartfile sql</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Expanded Operating Days (ExOD)</td><td class="data-plain">In Progress</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">The sql attached is to address the wrong HH cut times in the sql that was found just prior to going to prod.  <br><br>
 <br><br>
We felt it was best to load to prod and then come back to address.<br><br>
 <br><br>
Sql: <br><br>
<strong><span>drop</span></strong><strong><span>table</span></strong><span> hdp_smp.wrk_sf_edd_final;<br></span><strong><span>create</span></strong><strong><span>table</span></strong><span> hdp_smp.wrk_sf_edd_final </span><strong><span>as</span></strong><strong><span>select</span></strong><span> <br><br>dsn.dsn_lbl_id </span><strong><span>as</span></strong><span> dsn_lbl_id,<br>sort_loc </span><strong><span>as</span></strong><span> orig_loc_nbr, <br>dest </span><strong><span>as</span></strong><span> dest_loc_nbr, <br></span><span>'WEEKLY'</span><strong><span>as</span></strong><span> scan_period_cd,   <br></span><strong><span>concat</span></strong><span>(</span><span>'P'</span><span>,  <br> </span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_svc_days<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_svc_days<br>      </span><strong><span>else</span></strong><span> dest_svc_days </span><strong><span>end</span></strong><span>, </span><span>'D'</span><span>) </span><strong><span>as</span></strong><span> svc_dur_txt,<br>      <br>        </span><strong><span>case</span></strong><strong><span>when<br></span></strong><span>        (<br>      </span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end<br></span></strong><span>        ) = </span><span>'09:59'</span><strong><span>then</span></strong><strong><span>null</span></strong><span> <br>        </span><strong><span>else</span></strong><span> <br>        (<br>      </span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end<br></span></strong><span>        )<br>        </span><strong><span>end</span></strong><strong><span>as</span></strong><span> cut_tm,<br>        <br> </span><strong><span>round</span></strong><span>( (<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_error_pct<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_error_pct<br>      </span><strong><span>else</span></strong><span> dest_error_pct </span><strong><span>end</span></strong><span>) ,4) </span><strong><span>as</span></strong><span> calc_error_amt,<br><br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_pkg_cnt<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_pkg_cnt<br>      </span><strong><span>else</span></strong><span> DEST_pkg_cnt </span><strong><span>end</span></strong><strong><span>as</span></strong><span> tot_pkg_nbr<br>        <br>        ,<br>        </span><strong><span>int</span></strong><span>(<br>        </span><strong><span>case</span></strong><strong><span>when</span></strong><span> <br>        (<br>         </span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        )<br>        = </span><span>'09:59'</span><strong><span>then</span></strong><span> 24<br>        </span><strong><span>when</span></strong><span> <br>        </span><strong><span>substr</span></strong><span>((<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        ),1,2) = </span><span>'09'</span><strong><span>then</span></strong><span> 9 <br>        </span><strong><span>when</span></strong><span> <br>        </span><strong><span>substr</span></strong><span>((<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        ),4,2) &lt; </span><span>'29'</span><strong><span>then</span></strong><span> <br>        </span><strong><span>substr</span></strong><span>((<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        ),1,2)<br>        </span><strong><span>when<br></span></strong><span>        </span><strong><span>substr</span></strong><span>((<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        ),4,2) &gt; </span><span>'29'<br></span><span>        </span><strong><span>AND<br></span></strong><span>        </span><strong><span>int</span></strong><span>(</span><strong><span>substr</span></strong><span>((<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        ),1,2)) = 23<br>        </span><strong><span>Then</span></strong><span> 0<br>        </span><strong><span>else</span></strong><span> <br>              </span><strong><span>int</span></strong><span>(</span><strong><span>substr</span></strong><span>((<br></span><strong><span>case</span></strong><strong><span>when</span></strong><span> nlp1_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp1_error_pct &lt;= nlp2_error_pct </span><strong><span>then</span></strong><span> nlp1_cut_time<br>      </span><strong><span>when</span></strong><span> nlp2_error_pct &lt;= dest_error_pct </span><strong><span>and</span></strong><span> nlp2_error_pct &lt;= nlp1_error_pct </span><strong><span>then</span></strong><span> nlp2_cut_time<br>      </span><strong><span>else</span></strong><span> dest_cut_time </span><strong><span>end</span></strong><span> <br>        ),1,2)) + 1<br>        </span><strong><span>end<br></span></strong><span>        ) <br>        </span><strong><span>as</span></strong><span> db2_cut_tm<br>        <br></span><strong><span>from</span></strong><span> hdp_smp.wrk_sf_edd_final_comparison<br></span><strong><span>left</span></strong><strong><span>join</span></strong><span> hdp_smp.wrk_sf_dsn_lbl dsn<br>;</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Phil Crone</td><td></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount">4.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">4.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01347</td><td class="data-plain">Ability To Query eYMS Data</td><td class="data-plain"></td><td class="data-plain">eYMS Data Availability</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist  
I want the ability to query the data from eYMS 
So that I can look for unknown patterns, help others create useful reports and KPI data 
  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01348</td><td class="data-plain">Create A View/Table To Store Data From eYMS</td><td class="data-plain"></td><td class="data-plain">eYMS Data Availability</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a data scientist 
I want an unfiltered view(s)/table(s) to house all of the data from the eYMS topic/queue 
So that we will be able to use the data to measure KPI's, do predictive analytics, measure better and have a long term data store 
  
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02118</td><td class="data-plain">Finance Macro Forecasting Model</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Finance Macro Forecasting Model</td><td class="data-plain">In Progress</td><td class="data-amount">40.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Assist Finance in identifying data sources, data lake consolodation, and vendor model design/development structure so that macro forecasting efficiencies can be realized<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Erika Lynn Paulson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02119</td><td class="data-plain">GCP Design &amp; Architecture Collaboration</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">GCP Design &amp; Architecture Collaboration</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Collaborate with DnA I.T. regarding Data Science capabilities of GCP through MVP platform structure, conceptual architecture, self-service design, SLA/SLO's, etc. so that Data Science GCP needs are well defined and understood between DnA business and I.T.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Tony Scaldaferri</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02120</td><td class="data-plain">GCP Integration</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 1</td><td class="data-plain">GCP Integration</td><td class="data-plain"></td><td class="data-amount">20.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Integrate Data Science within GCP through use cases, data integration, lab work, sample deployments, and ongoing training so that Data Science leverages GCP capabilities as they become available for use and lead to future business benefit<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Clayton Clouse</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02121</td><td class="data-plain">GCP JDBC Spotfire Connector POC</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">GCP JDBC Spotfire Connector POC</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Develop and define a GCP JDBC Spotfire Connector Proof of Concept Use case so that GCP/Spotfire integration can be developed<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Jose Zenteno</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01895</td><td class="data-plain">PSSC: Data Catalog/Governance Tool Evaluation: Finalization of Vendor Scorecard for Data Governance Tool</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Vendor scorecard is a detailed evaluation tool to be used to rate a vendor along the Data Catalog/Data Governance line. <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Vendor Scorecard is<br>1) Reviewed and approved by Architecture and PSSC team<br><br>
2) Reviewed and approved by PO and other stakeholders<br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain">B-01896</td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01896</td><td class="data-plain">PSSC: Spike: Data Catalog/Governance Tool Evaluation: Vendor Evaluations/Discussions</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Vendor Evaluations/Discussions<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">1) Discuss with PSSC/Managers on short list of vendors to bring in to demo with<br><br>
2) Contact short list of Vendors for Prep sessions for Demo<br><br>
2) Have either a video conference or on-site demo with each Vendor<br><br>
2) Each vendor/tool's details are rated using the Vendor Evaluation Spreadsheet and is discussed with appropriate members of PSSC team and Evaluation team member<br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain">B-01897</td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">B-01895</td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01897</td><td class="data-plain">PSSC: Data Catalog/Governance Tool Evaluation: Additional discussions with leadership, finance, security, etc</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Additional discussions with leadership, finance, security, etc to finalize the vendor tool for Data Catalog/Governance tool<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>1) Discussions are had with necessary teams including leadership, finance, security etc to determine if approvals are necessary.</span><br><br>
<span>2) If needed, approval is signed off for each vendor (or only vendors we want to contract with) from leadership, finance, security, etc </span><br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">B-01896</td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01898</td><td class="data-plain">PSSC: Data Privacy Policy and principles walk through + Data Privacy Guidelines</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">4.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Policy and principles walk through with Angela Cherry + Data Privacy Guidelines</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    1. <span>PSSC Data Privacy leads are educated on the Data Privacy Guidelines (read)</span><br>
    2. PSSC Data Privacy leads complete a walk through with Risk Mgmt (Angela Cherry)<br>
</td><td class="data-plain">Alex Ovchinnikov</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01899</td><td class="data-plain">PSSC: Data Privacy Policy: Create GCP Data Privacy Policy</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span> Create GCP Data Privacy Policy - Link Jay's doc on data obfuscation, link with data security whitepapers</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance:</span><br><br>

    1. <span>Analyze the Data Privacy Policy (provided by Angela Cherry)</span><br>
    2. <span>Create a DnA Privacy Policy based on that from 1.</span><br>
    3. <span>The policy is reviewed internally with PSSC team</span><br>
</td><td class="data-plain">Alex Ovchinnikov</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01900</td><td class="data-plain">PSSC: Data Privacy Policy Runbook approval with Legal, InfoSec, DnA, and Risk Mgmt</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Runbook approval with Legal, InfoSec, DnA, and Cherry Team (Risk MGMT)</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span> Review and obtain approval with Legal, InfoSec, DnA, and Risk Mgmt (Cherry)</span><br><br></td><td class="data-plain">Alex Ovchinnikov</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01901</td><td class="data-plain">PSSC: Data Privacy Compliance: DnA to Complete InfoSec Required Data Privacy Module in FLC</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">Governance</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Each manager has assigned Data Privacy Fundamentals to their team members in FLC with a required completion date NLT May 29, 2019 .  Each manager must provide evidence that every member of their team is in compliance and has completed this FLC module. </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    1. <span>Ensure that all DnA IT and Data Science team members have completed Info-Sec required Data Privacy course in FLC</span><br>
    2. <span>Provide verification of compliance to InfoSec Risk Mangagement (report out to Angela)</span><br>
</td><td class="data-plain">Alex Ovchinnikov</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02122</td><td class="data-plain">Ground Operations Technology Forum</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Ground Operations Technology Forum</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Develop and create the Data Science deliverables for inclusion and presentation in the Ground Operations Technology Forum<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Nathan Cybak</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02123</td><td class="data-plain">IBPR Source Data and Measurement Accuracy</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">IBPR Source Data and Measurement Accuracy</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage P&amp;D Technology team to help identify data sources and measurement accuracy reporting scope related to the Inbound Package Report, so that the P&amp;D Technology team can improve the Inbound Package Report accuracy and more efficiently measure performance/results<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Tony Scaldaferri</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01937</td><td class="data-plain">Identify base metrics for operational support</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to build off “Strategy – Logging &amp; Metrics” to come up with our base metrics within the pipeline<br><br>
So they can give direction to implementation and increase DevOps.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Review with principle architects &amp; cloud team and implement feedback<br>
    • Review the updated section(s) in “Strategy – Logging &amp; Metrics” documentation<br>
    • Review each metric’s description and purpose<br>

<strong>Notes:  </strong>“Strategy – Logging &amp; Metrics” documentation (https://teams.microsoft.com/_#/docx/viewer/teams/https%3A~2F~2Fmyfedex.sharepoint.com~2Fsites~2FFXGIngestionTeam~2FShared%20Documents~2FGeneral~2FIngestion%20Framework%20Strategy~2FFW%20Component%20Strategies~2FStrategy%20%20-%20Logging%20and%20Metrics.docx?threadId=19%3A8a59748e3baa4)<br><br>
<strong>Dependency: </strong>N/A<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01938</td><td class="data-plain">Custom, common stack driver logging</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to implement custom logging to Stack Driver within each application of the ingestion framework<br><br>
So we get ease of insight into the pipeline beyond default logs.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate base metrics are across pipeline are visible in stack driver<br>
    • Validate code used for Kafka and DataFlow is common each for leveraging in future apps<br>

<strong>Notes</strong>:<br><br>

    • Stay aligned with Integration team on GCP (DataFlow) side<br>

<strong>Dependency</strong>:<br><br>

    • Completion of “Identify base metrics for operational support”<br>
</td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01939</td><td class="data-plain">Enveloping (payload wrapping)</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to create a capability for wrapping our payload with audit data<br><br>
So we can provide confidence and supportability with the ingestion process.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate enveloping approach is shared and agreed by others<br>
    • Validate action for initial wrapping is implemented<br>
    • Validate action for additional hops is implemented<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01940</td><td class="data-plain">Common format conversion function</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to create a function that standardizes all feeds to a common format<br><br>
So there can be consistency across the frameworks and the Advance Analytics Platform.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate various FedEx related types (XML, JSON, CSV) can be ran through conversion function<br>
    • Validate decided hop the action will be place and demo within the MVP pipeline<br>

<strong>Notes</strong>: Most likely implemented within dataflow and possibly standardizing to avro based on BigQuery benefits. Part of larger team discussion and google input<br><br>
<strong>Dependency</strong>:<br><br>

    • Decision from larger team<br>
    • Google suggestion for standardized format or format for use case (pipeline final target)<br>
</td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01941</td><td class="data-plain">timestamp and date conversion for BigQuery DF job</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to create a function to convert timestamp and date to a specified format<br><br>
So I can have reusable code for that transformation.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate code is reusable for other formats and DF jobs<br>
    • Validate successful conversion<br>
    • Validate load into BigQuery via templates (post transformation)<br>

<strong>Notes</strong>:<br><br>

    • Work with ingestion team, Jay has already written an initial approach<br>
    • See BigQuery requirements for both timestamp and date

        • https://cloud.google.com/bigquery/docs/loading-data<br>

<br>

<strong>Dependency</strong>:<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01942</td><td class="data-plain">actions for type conversion requirements</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to create additional actions as common code<br><br>
So that I can apply before loading into schema requirements within BigQuery<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate type conversion options are in common code<br>
    • Validate successful load into BigQuery<br>

<strong>Notes</strong>: Placeholder for the use case if we need to load to BigQuery, documenting transformations to be created based on schema requirements.<br><br>
<strong>Dependency</strong>:<br><br>

    • Use case’s schema(s) &amp; assuming load to BigQuery<br>
</td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">hold</td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01943</td><td class="data-plain">Add actions to DF template options</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to understand and test how different actions can be added as beam pipeline options<br><br>
So that I can configure what types of common code actions need to be applied to a given template deploy.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate 0 to many actions can be applied to a beam pipeline via options<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01944</td><td class="data-plain">investigate methods for capturing pubsub messageid within DF template</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to investigate options for capturing GCP Pub/Sub generated messagedID<br><br>
So that I we can provide confidence for the pipeline and have it available for wrapping, supporting and potentially deduping the pipeline.<br><br>
https://issues.apache.org/jira/browse/BEAM-3489 (https://issues.apache.org/jira/browse/BEAM-3489)<br><br>
https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage (https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage)<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate answers and suggestions from google<br>
    • Validate initial testing of common code for DF jobs sourcing pub/sub (degree of work may change based on Google’s response)<br>

<strong>Notes</strong>:<br><br>

    • Work with Cloud team and Google for getting initial questions answered

        • Documentation says duplicates are rare but possible, get clarification on that<br>
        • Ask if there are options for capturing within DataFlow job or what other people are doing<br>

<br>

<strong>Dependency</strong>: Time with google<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01945</td><td class="data-plain">add pubsub subscription as option</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a develop,<br><br>
I want to create common code for pubsub subscription option<br><br>
So that every template sourcing pubsub can use an existing subscriber when running.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate common code to be used for pub/sub sourcing templates<br>
    • Validate template has subscription as option<br>
    • Validate template successfully pulls messages from an existing subscriber<br>

<strong>Notes</strong>: Current template creates new subscriber at runtime<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01946</td><td class="data-plain">pubsubtobigquery windowing options batch vs streaming inserts</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to separate PubSubToBigQuery template into two<br><br>
So I can have separate pipeline builds depending on the use case need (streaming inserts or batch inserts)<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate two templates with their specific purpose<br>
    • Validate testing has been complete to show streaming inserts vs batch<br>

<strong>Notes</strong>: Batch insert for this job just means windowed.  It could be 2 mins or larger but the job itself is continuous.<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01947</td><td class="data-plain">pubsubtostorage deeper dive on windowing needs</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">hold</td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01948</td><td class="data-plain">GCS directories and file naming conventions and options</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to propose storage bucket directory and file naming standards<br><br>
So we can have a consistent configuration and approach for any DataFlow templates sinking to GCS.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate document covers data and configuration files<br>
    • Validate templates are updated for approach<br>
    • Validate test of updated template(s)<br>

<strong>Notes</strong>: This should be suggested standards for data and different configuration items that are stored in GCS (DF template, schemas, tmp dir, staging dir, etc)<br><br>
<strong>Dependency</strong>: send suggestion to principle architects and work with integration team<br><br></td><td class="data-plain">Chris Anteola,Blal Zafar,Justin Mauss</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01949</td><td class="data-plain">truncate vs append separate template</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01950</td><td class="data-plain">Build out parsing class for TableSchema BigQueryIO needs</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to create a separate class to handle BigQuery schema prep,<br><br>
So I don’t have an explicit transformation specified in every pipeline that sinks to BigQuery.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate new class that can process value to TableSchema<br>
    • Validate successfully added to template with BigQuery sink<br>

<strong>Notes</strong>: See ‘com.fedex.fxg.dna.templates.common.BigQuerySchema’ for JSON to TableSchema example and start of what we need to build and incorporate into templates<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01951</td><td class="data-plain">target as bigquery templates, break out create table logic</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to take out the logic of creating table in BigQuery<br><br>
So the DataFlow templates align with the assumption that it has already been created.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate template(s) are successful after taking out create table logic<br>
    • Validate new story created to handle create table logic elsewhere<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>: confirm approach with larger team before starting<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01952</td><td class="data-plain">Leverage security and governance strategy</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to validate GCS MVP definition and requirements with the ingestion framework MVP<br><br>
So I can ensure we aligned with GCS security and governance.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate ingestion framework alignment with GCS team’s MVP<br>
    • Validate core security standards defined by GCS team<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01953</td><td class="data-plain">Leverage retention management strategy (strategy WIP)</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01954</td><td class="data-plain">Create engagement document for pushing data to DnA using endpoint Description:</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01955</td><td class="data-plain">Implement ingestion REST service to Dev PCF</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate you can call REST service and it will send data to Pub/Sub<br>
    • Validate REST service is config driven (example: pubsub topic)<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>:<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01956</td><td class="data-plain">Design configuration for REST service</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01957</td><td class="data-plain">Leverage data pipeline validation strategy</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to build off Data Pipeline Validation strategy (https://teams.microsoft.com/_#/docx/viewer/teams/https%3A~2F~2Fmyfedex.sharepoint.com~2Fsites~2FFXGIngestionTeam~2FShared%20Documents~2FGeneral~2FIngestion%20Framework%20Strategy~2FFW%20Component%20Strategies~2Fstrategy-data-pipeline-validation.docx?threadId=19%3A8a59748e3baa43918f6a9)<br><br>
So I can work towards and complete the MVP scope.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>

    • Validate capability for testing methods on Kafka side<br>
    • Validate capability for testing methods on GCP side<br>
    • Validate testing tool suite selection<br>
    • Validate approach for future automation<br>

<strong>Notes</strong>:<br><br>
<strong>Dependency</strong>: Work with DevSecOps team on current testing tool options<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01958</td><td class="data-plain">Leverage CICD story</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01959</td><td class="data-plain">Leverage schema detection and handling strategy (strategy WIP)</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01960</td><td class="data-plain">Leverage centralized configuration strategy (pending sprint 5 work)</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01961</td><td class="data-plain">Leverage ingestion replay strategy (strategy WIP)</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01962</td><td class="data-plain">Leverage support and notification strategy</td><td class="data-plain"></td><td class="data-plain">Ingestion Framework v2</td><td class="data-plain">Ready</td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer,<br><br>
I want to develop email functionality to be triggered<br><br>
So I can tie it into failure scenarios of jobs within the ingestion framework.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><strong>Acceptance criteria</strong>:<br><br>
<strong>Notes</strong>:<br><br>

    • James Cramton is starting PDSM team engagement<br>

<strong>Dependency</strong>:<br><br>

    • Work with integration team<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01836</td><td class="data-plain">ISMP Sprint 1 Support (eRFS and HT)</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">ISMP PI 19.1 Support and NPW</td><td class="data-plain">Ready</td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">This story is to track the time spent on run the business activities</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01994</td><td class="data-plain">2.	Upgrade the DSS to HOS weekly netchange to a weekly refresh in CDC 11.4 in the dev environment.</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">As a: Manager of Shipment Reporting</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">I want: The DSS to HOS weekly netchange changed to a weekly refresh in the dev environment</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">So that: I can continue delivering information successfully</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The DSS to HOS weekly netchange will be set up as a weekly refresh in CDC 11.4 version in the dev environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01995</td><td class="data-plain">3.	Upgrade the DSS to HOS weekly netchange to a weekly refresh in CDC 11.4 in the QA environment</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">As a: Manager of Shipment Reporting</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">I want: The DSS to HOS weekly netchange changed to a weekly refresh in the qa environment</span><br><br>
 <br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">So that: I can continue delivering information successfully</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The DSS to HOS weekly netchange will be set up as a weekly refresh in CDC 11.4 version in the qa environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01996</td><td class="data-plain">5.	Upgrade the DSS to HOS weekly netchange to a weekly refresh in PROD</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">As a: Manager of Shipment Reporting</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">I want: The DSS to HOS weekly netchange changed to a weekly refresh in the prod environment</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">So that: I can continue delivering information successfully</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The DSS to HOS weekly netchange will be set up as a weekly refresh in CDC 11.4 version in the prod environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01998</td><td class="data-plain">12.	Promote and monitor the GPI refresh in prod</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Manager of GPI/Rating<br><br>
 <br><br>
I want: The GPI/Rating data feed to Pitt4 re-written as a refresh in the Production environment<br><br>
 <br><br>
So that: I can continue delivering information successfully<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The GPI/Rating data will be available in the Pitt4 files in the Production environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01999</td><td class="data-plain">13.	Rewrite and test the Complaints to CDAS subscription as a refresh in dev</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Manager of CDAS<br><br>
 <br><br>
I want: The Complaints data feed to CDAS re-written as a refresh in the dev environment<br><br>
 <br><br>
So that: I can continue delivering information successfully<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The Complaints data will be available in the CDAS files in the dev environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02000</td><td class="data-plain">14.	Test the Complaints to CDAS refresh subscription in QA</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Manager of CDAS<br><br>
 <br><br>
I want: The Complaints data feed to CDAS re-written as a refresh in the QA environment<br><br>
 <br><br>
So that: I can continue delivering information successfull<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The Complaints data will be available in the CDAS files in the QA environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02001</td><td class="data-plain">15.	Promote and monitor the Complaints to CDAS refresh subscription in prod</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Manager of CDAS<br><br>
I want: The Complaints data feed to CDAS re-written as a refresh in the Production environment<br><br>
 <br><br>
So that: I can continue delivering information successfully<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>The Complaints data will be available in the CDAS files in the Production environment</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02002</td><td class="data-plain">16.	Clean up old subscriptions in Management Console from previous version</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">As a: Manager of Data Analytics and Ingestion</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">I want: The Management Console cleaned up by removing all subscriptions from the old versions</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">So that: there is no confusion on what subscriptions are current for support purposes</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>All old subscriptions that are no longer running will be removed from Management Console.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02003</td><td class="data-plain">17.	Disable monitors and restart jobs on old servers no longer used</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">As a: Manager of Data Analytics and Ingestion</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">I want: All monitors and the restart jobs disabled on all of the old servers that are no longer used</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">So that: there is no chance of any old subscriptions being restarted while the newest version is running</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>No more monitors and restart jobs will be running on the old servers. This can be verified by looking at the logs.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02004</td><td class="data-plain">18.	Identify and decommission all dev, qa, and prod CDC servers no longer needed</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">JT: CDC 11.4 Upgrade in Prod</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">As a: Manager of Data Analytics and Ingestion</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">I want: The dev, qa, and prod CDC servers that are no longer used to be identified and decommissioned</span><br><br>
<span style="font-size: 10pt; font-family: 'arial' , sans-serif; color: #404040;">So that: there is no unnecessary work done such as patches and upgrades if the servers are no longer needed</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Acceptance Criteria: </span><br><br>
<span>All old CDC servers are identified and requests are sent to the SA teams to notify them that the servers can be decommissioned</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02021</td><td class="data-plain">Work with iSeries support to design the automated DR solution</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">JT: CDC Portal DR configured failover process</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the iSeries support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC Portal DR process fully automated and a solution documented</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that the development teams can complete the scripting needed to automate the CDC Portal DR process.  </span><br><br>
 <br><br>

















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">A recommendation from IBM on the solution</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">A completed design documentation for the automation process</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02022</td><td class="data-plain">Complete iASP setup for CDC</td><td class="data-plain"></td><td class="data-plain">JT: CDC Portal DR configured failover process</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the iSeries support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC Portal DR system configured on the iASP so CDC can run on both CDC1 and CDC1M using Power HA</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that we can complete the CDC Portal setup and test the CDC DR automation scripts.  </span><br><br>
 <br><br>

















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">CDC is configured on the iASP so it can run on both CDC1 and CDC1M.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">CDC DR testing is completed to verify that CDC can run on both primary and secondary systems. </span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02023</td><td class="data-plain">Complete DR automation scripts</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">JT: CDC Portal DR configured failover process</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the iSeries support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC Portal DR automation scripts developed and ready for testing on the CDC Portal.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that the DR procedures can be automated for the CDC Portal instances.  </span><br><br>
 <br><br>
 <br><br>

Show Less... ()
















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">iSeries scripts completed and tested to automate the CDC failover for each of these systems:  PITT1, PITT5, and OPS1.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02016</td><td class="data-plain">QA: CDC Oracle 12c upgrade for VMS QA</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">JT: CDC Upgrade Oracle 12c</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the Oracle DBA support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC application configured to use the Oracle 12c VMS qa database.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that we can upgrade the VMS qa database databases to Oracle 12c to be compliant with Oracle support.</span><br><br>
 <br><br>

















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC VMS instance is updated to the Oracle 12c VMS qa database.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC VMS subscriptions are tested and verified to work correctly in the Oracle 12c database.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC linux scripts are tested and work correctly with Oracle 12c.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02017</td><td class="data-plain">PROD: Install CDC on the new Oracle 12c TMS PROD server</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">JT: CDC Upgrade Oracle 12c</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the Oracle DBA support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC application installed on the Oracle 12c servers for the TMS prod database.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that we can upgrade the TMS prod database databases to Oracle 12c to be compliant with Oracle support.</span><br><br>
 <br><br>

















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">CDC is installed on the TMS prod database server.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The Oracle tnsnames file is updated with the CDC connections.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">CDC has access to the redo/archive logs on the prod database server.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02018</td><td class="data-plain">PROD: Migrate CDC subscriptions to new Oracle 12c TMS PROD instance</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">JT: CDC Upgrade Oracle 12c</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the Oracle DBA support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC subscriptions migrated to the new Oracle 12c instance for TMS prod.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that we can upgrade the TMS prod database databases to Oracle 12c to be compliant with Oracle support.</span><br><br>
 <br><br>

















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC subscriptions were successfully migrated and tested in the new TMS prod instance.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The Linux scripts were migrated and verified on the new TMS prod database server.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">All One Automation jobs are updated with the new hostgroup for prod.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02019</td><td class="data-plain">PROD: CDC Oracle 12c upgrade for VMS PROD</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">JT: CDC Upgrade Oracle 12c</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">

















<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the Oracle DBA support team</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC application configured to use the Oracle 12c VMS prod database.  </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that we can upgrade the VMS prod database databases to Oracle 12c to be compliant with Oracle support.</span><br><br>
 <br><br>

















</td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC VMS instance is updated to the Oracle 12c VMS prod database.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC VMS subscriptions are verified and working correctly in the Oracle 12c database.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">The CDC linux scripts are verified and working correctly with Oracle 12c.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01257</td><td class="data-plain">Create access to vrh* servers for Deep and Michael Fritts team members</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Create access to vrh* servers for Deep and Michael Fritts team members</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01259</td><td class="data-plain">Determine folder structure for kafka set up (ex: /opt/kafka, /var/kafka (data), figure out for log files)</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01260</td><td class="data-plain">Determine folder structure for zookeeper set up (ex: /opt/zookeeper, /var/zookeeper (data), figure out for log files)</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Skynet T-6000</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01265</td><td class="data-plain">Set up few topics for evaluation purpose</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01266</td><td class="data-plain">Set up the kafka cluster with multi node</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01267</td><td class="data-plain">Set up the zookeeper with multi node</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Skynet T-6000</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01268</td><td class="data-plain">Setup OVO (Open View operation which is on HP monitoring tool)</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01516</td><td class="data-plain">Determine how to monitor instrument/monitor kafka cluster</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: 
  
I want: 
  
So that: 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Skynet T-6000</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01757</td><td class="data-plain">Create linux system user kafka (with naming conventions that kafkadev, kafkaqas, kafkaprd)</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Create linux system user kafka (with naming conventions that kafkadev, kafkaqas, kafkaprd)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01761</td><td class="data-plain">Install Kafka cluster in vrh* servers</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Install Kafka cluster in vrh* servers</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01762</td><td class="data-plain">Install Kafka Manager</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Install Kafka Manager for kafka monitoring</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01763</td><td class="data-plain">Install Zookeeper in vrh* servers</td><td class="data-plain"></td><td class="data-plain">Kafka cluster</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Install Zookeeper in vrh* servers</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Govind Reddy Akkala (OSV)</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01967</td><td class="data-plain">JMS Connector to Kafka</td><td class="data-plain"></td><td class="data-plain">Kafka GCP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01968</td><td class="data-plain">Define strategy for ingestion topics</td><td class="data-plain"></td><td class="data-plain">Kafka GCP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>Description</strong>:<br><br>

    1. Use a mega topic for ingestion<br>
    2. Use topic per pipeline<br>
    3. Use combination of the two<br>
    4. This decision should be made to drive how the http Kafka consumer is written<br>
</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01969</td><td class="data-plain">Strategy to implement topic and broker operational metrics</td><td class="data-plain"></td><td class="data-plain">Kafka GCP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>Description</strong>: Define which metrics are valuable<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01970</td><td class="data-plain">Message Type and conversion implementation</td><td class="data-plain"></td><td class="data-plain">Kafka GCP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>Description</strong>:<br><br>

    • Standardize how to manage different message types. XML, JSON, delim, fixed, etc.<br>
    • Define standards for recommendations for new datasets on how they should be built. For example: JSON format, Data fields format, etc. This should become a public facing guide for consumers of ingestion framework<br>
</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-01971</td><td class="data-plain">Security / governance need to be placed around rest calls to and from GCP applications</td><td class="data-plain"></td><td class="data-plain">Kafka GCP</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><strong>Description</strong>:<br><br>

    • Decide if we have anything to manage after google cloud start meetings<br>
    • Create strategy and implement the strategy if needed<br>
</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02124</td><td class="data-plain">Leverage Package Data (Dims, Weights, etc.)</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Leverage Package Data (Dims, Weights, etc.)</td><td class="data-plain">In Progress</td><td class="data-amount">40.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support CIE team with weight and dimension accuracy analysis, outlier detection modelling, and DnA feature specifications for long term data pipeline so that Customer Information Engineering has actionable data insights<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Angela Kao</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01343</td><td class="data-plain">Linehaul Visualizations</td><td class="data-plain"></td><td class="data-plain">Linehaul Visualizations</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Collaborate with L/H and I.T. teams to productionalize P.O.C. L/H equipment dashboards so that L/H teams gain supported insight analytics</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Jose Zenteno</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01830</td><td class="data-plain">Review details and requirements of the Linehaul dashboard with Data Science team</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Linehaul Visualizations</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Understand and establish the best course of action, considering the following: 
Number of users 
Size of data and retrieval 
Speed of availability (caching) 
Performance validation 
  
  
  
Acceptance Criteria: 
Dashboard and related objects are validated, best practices are applied, and the dashboard is approved for QA or production deployment.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01865</td><td class="data-plain">FIRST request for infrastructure (continued from 19.1 iteration 4)</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">LPSAP 0.5</td><td class="data-plain">In Test</td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"><span>As a development team</span><br><br>
<span>I want to raise a FIRST request (FedEx InfoSec review &amp; Secure Project Tracking) for the LPSAP infrastructure</span><br><br>
<span>So that we can ensure that LPSAP adheres to InfoSec standards/policies &amp; compliance with applicable regulations.</span><br><br>
 <br><br>
<span> </span><br><br>
<span>Notes :   </span><br><br>
<span> </span><span>Chris Sproull is SME for IT PGH</span><br><br>
<span> </span><br><br>
<strong><span>FIRST Requester Responsibilities</span></strong><br><br>
<span>Create FIRST project requests</span><br><br>
<span>Enter detailed project description</span><br><br>
<span>Complete &amp; submit project review screening questions</span><br><br>
<span>Attach relevant supporting documentation – Design, Workflows, data fields, SOWs, etc.</span><br><br>
<span>Complete all relevant domain questions</span><br><br>
<span>Reply to FIRST Coordinator and InfoSec domain SME questions</span><br><br>
<span> </span><br><br>
<strong><span>Time Frame </span></strong><em><span>(this provides a couple SLA’s, but still a large grey area in the middle)</span></em><br><br>
<span>Between Submission Process InfoSec Domain SMEs will have 5 business days to respond with comments.</span><br><br>
<span>Requesters will receive updates on approvals and comments.</span><br><br>
<span>As soon as the InfoSec Domain SMEs provide comments respond.</span><br><br>
<span>Once all is approved a security pass will be given for the FIRST.</span><br><br>
<span>Could take up to 1 month depending on InfoSec Domain SMEs review and FIRST requester.</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>Submit FIRST request through InfoSec (COMPLETED in Iteration 2 but additional info was required)</span><br><br>
<span>Get the FIRST review completed by receiving Approval</span><br><br></td><td class="data-plain">Markus Reimers</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount">5.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">5.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02125</td><td class="data-plain">Medline/Customer Shipment Change D.O. POC</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Medline/Customer Shipment Change D.O. POC</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Support eight Value Streams with assigned Data Scientist(s) so that Value Streams can identify future Data Science needs when planning Value Stream work<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Kimberly Jane Rice</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02126</td><td class="data-plain">Micro Forecasting/Single Source of Truth</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Micro Forecasting/Single Source of Truth</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage MOON PMO and Operations Research to define scope around Single Source of Package Truth, Shipper Profiling, Weather and EPDI/EPV data so that all these work streams are considered towards the support of a real time micro volume forecast.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Nathan Cybak</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02208</td><td class="data-plain">GPI Documentation</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">MOON Enabler - DnA Application Rationalization</td><td class="data-plain">Ready</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a: Manager responsible for GPI/Rating</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;"> </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want: To document all the files, tables, CDC subscriptions, scripts, one automation jobs, used in the GPI/Rating environment. </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;"> </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that: I can identify the entire process to add in app rationalization decisions and 3rd party support.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;"> </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">Acceptance Criteria: The GPI/Rating process is documented. </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02209</td><td class="data-plain">SVM Documentation</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">MOON Enabler - DnA Application Rationalization</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want: To document all the files, tables, CDC subscriptions, scripts, one automation jobs, used in the SVM environment. </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;"> </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that: I can identify the entire process to add in app rationalization decisions and 3rd party support.</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;"> </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">Acceptance Criteria: The SVM process is documented. </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02127</td><td class="data-plain">MOON/Blackjack Rollout Dashboard</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">MOON/Blackjack Rollout Dashboard</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage MOON FLM teams for data needs and dashbaord design so that the proper Blackjack/DRO measurements can be visualized indicating rollout success and failure metrics<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Brandon Walker</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01294</td><td class="data-plain">[Placeholder] Create dummy pipelines</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Takes data from source and place in sink with little to no changes to data to help prove out and provide learning experience.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01298</td><td class="data-plain">[Placeholder] Implement Security Standards</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Implement the security standards defined by Paper Street Paper Company</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01780</td><td class="data-plain">[Placeholder] Create automated testing framework</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Create the framework that we can do automated test in.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01781</td><td class="data-plain">[Placeholder] Create data pipeline</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Create data pipeline that meets the use cases</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01783</td><td class="data-plain">[Placeholder] Data Architecture</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Determine the data architecture for what and how we are placing the data</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01784</td><td class="data-plain">[Placeholder] Implement Metadata Items</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">This is meant to show that we need to implement metadata as part of the pipeline</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01785</td><td class="data-plain">[Placeholder] Implement Operational Excellence</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Implement the Operational Excellence standards such as logging, metrics, and KPIs</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01787</td><td class="data-plain">[Placeholder] Training</td><td class="data-plain"></td><td class="data-plain">MVP Prod Release 1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Placeholder for either training or time allocate for people to learn</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01176</td><td class="data-plain">Bridge and Reporter configuration</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Establish the bridge and reporter configurations within the cluster 
So that: Web and run server hosts can communicate properly 
A/C: Bridge and reporter services for new cluster can be seen within Control center</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01186</td><td class="data-plain">Create application users</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team to create all necessary application users on all new Ab Initio servers 
So that: The following user accounts can exist: sbiPROD, sbiPRODs, sbiown  and abadmin 
A/C: user accounts exist: sbiPROD, sbiPRODs, sbiown  and abadmin</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01190</td><td class="data-plain">Create sudo role</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team that the abinitiocm sudo role is created on all new Ab Initio servers  
So that: I have the required permissions and roles to complete my job 
A/C: Have the permission and sudo roles</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01192</td><td class="data-plain">Create sudo role</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team that the abinitiocm sudo role is created on all new Ab Initio servers 
So that: I have the required permissions and roles to complete my job 
A/C: Have the permission and sudo roles</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01205</td><td class="data-plain">GDE Setup</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want: to setup the GDE to checkout the projects and do the required changes to the sandbox parameters. 
So that: i can checkout/checkin the changes to projects and changes to the sandbox parameters. 
Acceptance Criteria: Able to test the connection successfully and do the checkouts/checkin and modify the  required parameters</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01207</td><td class="data-plain">Identify features/Themes for PI 19.1+ implementation</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Architecture Team</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01218</td><td class="data-plain">Oracle DB connection</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Establish a connection to the Oracle database repository 
So that: Control center can utilize the existing database 
A/C: Connection to the oracle db</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01221</td><td class="data-plain">Passwordless server setup</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Configure a Passwordless setup on all servers 
So that: SSH connections can be made without needing a password 
A/C: Show that SSH connections can be made between the nodes</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01227</td><td class="data-plain">PE-EL: SPIKE: Dummy Terminal Zip Assignment</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to create a logic flow of the dummy zip alignment  
So that we can be better prepared to make changes to the logic to account for business plans and growth 
AC 
Flow as you go created</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01238</td><td class="data-plain">Request mount points</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team to modify the mount points to reflect the vendors recommendations 
So that: The cloud Abinitio cluster is sized properly. 
A/C: AB cluster is sized to the vendors recommendations. /var/fedex 500gb, /opt/fedex 50 gb</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01240</td><td class="data-plain">Request mount points</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team to modify the mount points to reflect the vendors recommendations 
So that: The cloud Abinitio cluster is sized properly. 
A/C: AB cluster is sized to the vendors recommendations. /var/fedex 500gb, /opt/fedex 50 gb</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01243</td><td class="data-plain">Spring Cloud dataflow server</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a developer I want to have recent version of approved open source versions of Spring cloud dataflow server and related components so that I am staying current with Spring releases and take advantages of new features and bug fixes in old framework</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">5.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01245</td><td class="data-plain">Understand Data &amp; develop schema</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01250</td><td class="data-plain">Update SBIS biaCluster to java 1.8</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Update SBIS biaCluster to java 1.8</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01420</td><td class="data-plain">Acquire Server Keys</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Acquire the set of server keys from Ab Initio vendor 
So that: A passwordless configuration of the cluster can be established 
A/C: Passwordless configured established on the cluster.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01421</td><td class="data-plain">Acquire Server Keys</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Acquire the set of server keys from Ab Initio vendor 
So that: A passwordless configuration of the cluster can be established 
A/C: Passwordless configured established on the cluster.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01423</td><td class="data-plain">Add Server Keys</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Assign the Ab Initio server keys to each node within the cluster 
So that: A harmonious connection can be established to and from other data sources outside the cluster 
A/C:  Servers are updated with new license keys and accessible to the other servers 
Note: Need to validate license keys are proper</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01425</td><td class="data-plain">Add Server Keys</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Assign the Ab Initio server keys to each node within the cluster 
So that: A harmonious connection can be established to and from other data sources outside the cluster  
A/C:  Servers are updated with new license keys and accessible to the other servers 
Note: Need to validate license keys are proper</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01428</td><td class="data-plain">Apphub and Abinitiorc configuration</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Identify the work and data directories 
So that: apphubrc &amp; abinitiorc and be configured properly 
A/C: AB home settings match vendors recommendation</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01429</td><td class="data-plain">Bridge and Reporter configuration</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Establish the bridge and reporter configurations within the cluster 
So that: Web and run server hosts can communicate properly 
A/C: Bridge and reporter services for new cluster can be seen within Control center</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01432</td><td class="data-plain">Build Multifle system</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Build the MFS file system on each server 
So that: The proper file structures and partitioning methods are established 
A/C: Multiple partition are present for each file.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01442</td><td class="data-plain">Create project folders</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: AB Developer  
I want: create project folders for Skynet  
So that: Can Develop new requirements Skynet. 
A/C: all project data directories from SP AB cluster exist. 
  
Test plan: 
Acceptance Criteria:</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01443</td><td class="data-plain">Create project folders *Discuss with Skynet</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: AB admin  
I want: create project directories as directed by the Skynet team  
So that: They can develop new requirements Skynet.team 
A/C: All project data directories from SP AB cluster exist. 
Skynet team accepts directories are in place 
  
Test plan: 
  
  
Note: Will need to refine further with Skynet Team</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01449</td><td class="data-plain">Deploy to L4/Prod - fxsp-exemption-exclusion-ui remove ojdbc</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Deploy to L4/Prod - fxsp-exemption-exclusion-ui remove ojdbc</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01471</td><td class="data-plain">Oracle DB connection</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Establish a connection to the Oracle database repository 
So that: Control center can utilize the existing database 
A/C: Connection to the oracle db</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01480</td><td class="data-plain">PE-EL: LEARNING SPIKE: Spring Cloud</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As an IT Analyst 
I want to learn more about Spring Cloud 
so that I have a better understanding</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01481</td><td class="data-plain">PE-EL: SPIKE: Dummy Terminal Logic</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to create a logic flow of the current Dummy Terminal Logic process 
So that we can be better prepared to make changes to the logic to account for business plans and growth 
AC 
Flow as you go created</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01486</td><td class="data-plain">PI 19.1 Feature Breakdown</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Skynet T-6000</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01661</td><td class="data-plain">Ab Initio Batch Job</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">7.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">1. 
Read Ab
 Initio Queue
 
2. 
Create zip file
 
3. 
Write flat file to hdfs staging directory</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01670</td><td class="data-plain">Apphub and Abinitiorc configuration</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Identify the work and data directories 
So that: apphubrc &amp; abinitiorc and be configured properly 
A/C: AB home settings match vendors recommendation</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01678</td><td class="data-plain">Build Multifle system</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Build the MFS file system on each server 
So that: The proper file structures and partitioning methods are established 
A/C: Multiple partition are present for each file.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01680</td><td class="data-plain">Connectivity to external data sources</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Confirm that Teradata/Oracle/Hadoop connections are established 
So that: Ab Initio can successfully interface with external data sources 
A/C: Connectivity to external sources from the new cloud server</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01683</td><td class="data-plain">Create application users</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Request from the CloudOps team to create all necessary application users on all new Ab Initio servers 
So that: The following user accounts can exist: sbidev, sbiqas, sbiown  and abadmin 
A/C: user accounts exist: sbidev, sbiqas, sbiown  and abadmin</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01694</td><td class="data-plain">Disk evaluation</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Evaluate disk allocation settings 
So that: Confirmation of storage parameters meeting the Vendors specifications 
A/C: Disk allocation meet vendors recommendations</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01697</td><td class="data-plain">Existing DEV Co-operating system upgrade</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Upgrade the existing Ab DEV environment from 3.3.2.3 to version 3.3.3.11 
So that: We can utilizing the existing EME and Control center moving forward 
A/C:  Run AB commands to validate the existing EME 
 
Note: Dev Only task, not QAS</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01700</td><td class="data-plain">fxsp-customer-support-portal upgrade to Java 1.8</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">fxsp-customer-support-portal upgrade to Java 1.8</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01701</td><td class="data-plain">fxsp-exemption-exclusion-ui Upgrade to Java 1.8</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">fxsp-exemption-exclusion-ui Upgrade to Java 1.8</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01702</td><td class="data-plain">fxsp-operational-service-management-portal-ear Upgrade to Java 1.8</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">fxsp-operational-service-management-portal-ear Upgrade to Java 1.8</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01703</td><td class="data-plain">GDE Setup</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want: to setup the GDE to checkout the projects and do the required changes to the sandbox parameters. 
So that: i can checkout/checkin the changes to projects and changes to the sandbox parameters. 
Acceptance Criteria: Able to test the connection successfully and do the checkouts/checkin and modify the  required parameters</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01705</td><td class="data-plain">GDE Setup</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want: to setup the GDE to checkout the projects and do the required changes to the sandbox parameters. 
So that: i can checkout/checkin the changes to projects and changes to the sandbox parameters. 
Acceptance Criteria: Able to test the connection successfully and do the checkouts/checkin and modify the  required parameters</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01707</td><td class="data-plain">Innovation</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Skynet T-6000</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01718</td><td class="data-plain">Passwordless server setup</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Configure a Passwordless setup on all servers 
So that: SSH connections can be made without needing a password 
A/C: Show that SSH connections can be made between the nodes</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01722</td><td class="data-plain">PE-EL: LEARNING SPIKE: Bootstrap Training</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As an IT analyst 
I want to learn bootstrap 
so I have a better understanding</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01723</td><td class="data-plain">PE-EL: LEARNING SPIKE: NPM Training</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As an IT analyst 
I want to learn NPM 
so that I have a better understanding</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01727</td><td class="data-plain">PE-EL: SPIKE: Trailer Exclusions for Sunday Sorts</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to find a definitive way to allow Sunday sort dates to be entered as a start date for trailer exclusions 
So that Sunday sorts for ExOD are taken into consideration for Trailer Exclusions (TR) 
AC 
Flow as we go for new solution 
  
  
NOTE for Modernization:  
Can we use TMS sort schedules to determine day before/after use?</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01740</td><td class="data-plain">SmartFile Spark Aggregation</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01748</td><td class="data-plain">Update osmCluster to Java 1.8</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Update osmCluster to Java 1.8</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01751</td><td class="data-plain">Update Spring fxsp-operational-service-management-portal-ear (continued from story #301278)</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Update Spring fxsp-operational-service-management-portal-ear (continued from story #301278)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01752</td><td class="data-plain">Update Weblogic SBIS biaCluster to run Java 8</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">Update Weblogic SBIS biaCluster to run Java 8</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01753</td><td class="data-plain">Validation Testing</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Complete validation testing of the new DEV Ab Initio environment 
So that: We can confirm that EME, GDE, and Control Center are performing properly 
A/C:  
 
Successful execution of graphs.   
Check-in and checkout of code.  
Test jobs of restarting servers.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01843</td><td class="data-plain">Add Server Keys</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Assign the Ab Initio server keys to each node within the cluster 
So that: A harmonious connection can be established to and from other data sources outside the cluster  
A/C:  Servers are updated with new license keys and accessible to the other servers 
Note: Need to validate license keys are proper</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01844</td><td class="data-plain">Acquire Server Keys</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: IT Admin 
I want to: Acquire the set of server keys from Ab Initio vendor 
So that: A passwordless configuration of the cluster can be established 
A/C: Passwordless configured established on the cluster.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01209</td><td class="data-plain">Installing Spotfire Linux components on prh56016 and prh56017 servers.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Spotfire Administrator 
I want: To install the Linux Spotfire components on the prh56016 &amp; prh56017 servers 
So That: The servers are added to the cluster of the PROD environment  
Business Value: Servers can be utilized in the current Spotfire PROD cluster 
Test Plan(s): Checking if all the installed components are visible in the cluster 
Acceptance Criteria: Checking if all the installed components are visible in the cluster</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01210</td><td class="data-plain">Installing Spotfire Node Manager on pwn56023 and pwn56024 Windows servers.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As A: Spotfire Administrator 
I want: To install the Linux Spotfire components on the pwn56023 &amp; pwn56024 servers 
So That: The servers are added to the cluster of the PROD environment  
Business Value: Servers can be utilized in the current Spotfire PROD cluster 
Test Plan(s): Checking if all the installed components are visible in the cluster 
Acceptance Criteria: Checking if all the installed components are visible in the cluster</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01212</td><td class="data-plain">Modify and verify the configurations of newly added servers are same as existing servers in the cluster.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Spotfire Administrator 
I want: to modify and verify the configurations of the newly added servers  
So that: they are the same configurations as the existing servers in the cluster 
Test plan: Verifying that the same configurations on the newly added servers are the same as the rest of the servers in the cluster.  This includes configuration for maps on webplayer server and other settings related to the webplayer servers and automation services.  
Acceptance Criteria: The configurations on all of the PROD servers are the same.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01435</td><td class="data-plain">Configure the newly added servers to use the load balancer SSL certificates.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Spotfire Administrator 
I want: to configure the newly added servers in the PROD environment 
So that: they can use the load balancer SSL certificates 
Test plan: Modify the server.xml file and copy the load balancer certificates onto the server 
Acceptance Criteria: the current load balancer SSL certificates are added and visible on the PROD servers.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01233</td><td class="data-plain">PI 19.1 Sprint 5: KLO - Support / Ad-Hoc / Unplanned</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01251</td><td class="data-plain">Update Server documentation.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As A: BI Architect 
I want: to document all the cluster/server changes 
So That: FXG has an up-to-date architecture description available 
Business Value: Architecture document will help to socialize server information and structure 
Test Plan(s): Document needs to be verified by Admins and Architects 
Acceptance Criteria: Document passed validation and published on FXG Spotfire Sharepoint folder</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01455</td><td class="data-plain">Fix error handling in Acquisition Consolidation script</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">Fix the Acquisition consolidation script so that it handles errors and does not default to going to the next step. 
Specific issue is speeds files are deleted when job completes so data is lost.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Skynet T-6000</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01468</td><td class="data-plain">One Automation - Time overrun alert</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 4</td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain">In Progress</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">If specific jobs (to be identified) take longer than 2 hours to run than a minor alert should be generated.   
  
Acceptance Criteria: 
Critical jobs identified and max runtime identified 
Send findings to team 
Request submitted to 1A team to raise minor incident when max runtime exceeded</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Yogesh Sharma</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">5.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">3.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01489</td><td class="data-plain">PI 19.1 Sprint 5: KLO - Support / Ad-Hoc / Unplanned</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">Team agrees to capture: 
Support Hours 
Production Support 
Access Requests
Protect Purple Work
Unplanned Ad-Hoc Requests
 After planning ART Request
Other teams requesting time outside of the plan.
Urgent User Requests.
Details; 
*Where Applicable: Who 
How Long? 
Off Hours? 
What did we do? 
Events - Non Recurring / Non Common one time work efforts.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01503</td><td class="data-plain">Unplanned - Security Vulnerability</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 4</td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain">In Progress</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">From: FedEx Vulnerability Elimination/Remediation vert@fedex.com&gt;
 Date: February 4, 2019 at 4:09:37 PM GMT+5:30
 To: eep.dwivedi@fedex.com&gt;
 Subject: InfoSec AVERT: Event Digest Message 
AVERT Digest Message for Deep Dwivedi (433484) - Mon, 04 Feb 2019 04:39:37 CST 
Summary of Events for which you are the Remediation Owner: 
  
  
 
  
  
  
From: Chris Sproull 
 Sent: Monday, February 25, 2019 2:41 PM
 To: Jay Varner  Cc: Daniel Rindt  Deep Dwivedi  Subject: RE: Details for avert 
  
Jay, 
 I just talked to Daniel.  I have a meeting with the Linux server team this week.   
  
The vulnerability modifier is the port being used.  If this is not used by your application then this should not be your AVERT. 
  
I want to touch base with the Linux server team and then either myself or the AVERT delegates will send out a note on what to do with these AVERTS.  Please hold tight and I’m working on a resolution this week on who is accountable.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Jay Varner</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">2.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Big Poppa&#39;s Revenge</td><td class="data-amount">3.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01710</td><td class="data-plain">Modify and validate the PROD load balancer URL to utilize both prh56016 and prh56017 spotfire servers.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a: Spotfire Administrator 
I want: to Modify and test the existing load balancer 
So that: I can utilize the prh56016 &amp; prh56017 servers 
Test plan: Using the csm.html file to check if the prh56016 &amp; prh56017 servers are utilized by the load balancer. 
Acceptance Criteria: Using the csm.html file to check if the prh56016 &amp; prh56017 servers are utilized by the load balancer.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01741</td><td class="data-plain">Spotfire Metadata Validation.</td><td class="data-plain"></td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As A: Spotfire Aministrator 
I want: to validate the metadata DB performance 
So That: the increased number of nodes will not impact the performance of the metadata database 
Business Value: Eliminate the constraints on the Spotfire backend structure 
Test Plan(s): Validate Oracle metadata DB performance and response times 
Acceptance Criteria: New Nodes are communicating with metadata DB as they are today per server</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01861</td><td class="data-plain">PI 19.1 Sprint 5: KLO - Support / Ad-Hoc / Unplanned</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">Orphan Migrated Items - FXG DnA CY19 PI1</td><td class="data-plain">Working on It</td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">Team agrees to capture: Support Hours Production Support Access Requests Protect Purple Work Unplanned Ad-Hoc Requests After planning ART Request Other teams requesting time outside of the plan. Urgent User Requests. Details; *Where Applicable: Who How Long? Off Hours? What did we do? Events - Non Recurring / Non Common one time work efforts.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount">22.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount">22.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01721</td><td class="data-plain">PE-EL: KLO Help Tickets Hub and Station Reporting</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: KLO - High Priority PI 2019.1</td><td class="data-plain">In Development</td><td class="data-amount">7.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">PE-EL: KLO Help Tickets Hub and Station Reporting</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Paul Ray</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">5.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">5.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01390</td><td class="data-plain">PE-EL: SPIKE: Find Trailer Export Bug (Move to 2019.1)</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO - High Priority PI 2019.1</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As owner of trailer exclusions 
I want to have the current export issues of the Trailer Exclusion Review Screen identified. 
So that a solution can be developed 
AC 
Records causing export failures identified. 
Data / Application root cause identified. 
Identify solution</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">3.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">3.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01055</td><td class="data-plain">PE-EL:  EDW send query moved to AbInitio  **FEATURE LEVEL**</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the development team 
I want to change the current EDW send query to AbInitio 
So that data is transferred to SQI timely 
A.C. 
Faster Ground data can be passed into EDW for SQI 
Validate that it pulled the same data as the old way 
NOTE: 
Also checking for invalid data and clear fileld to blank or null and fill in country code when missing</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01061</td><td class="data-plain">PE-EL: Dummy terminal logic change (MODERNIZATION)</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the delivery quality department 
I want the dummy terminal logic to change 
So that it is not represented by a separate MST050 but by additional days to MST050 either by origin or destination postal/zip code (replace calculations) 
A.C. 
Dummy terminal assignment removed 
Add additional days to MST050 (instead of a duplicate MST050 entry) 
Dummy terminal logic within Initial Commit logic matches Service  
  
Notes: 
File name is SVMPF855 - screen name is SVM855RU</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01063</td><td class="data-plain">PE-EL: LEARNING SPIKE: Angular 6 Training</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain">In Progress</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a development Team 
I want to learn Angular 6 
So that I can create a modern UI for LPSAP 
  
Notes: 
Courses on PluralSight, Udemy, YouTube 
Courses should include Unit Testing and combination with Spring Boot</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">49.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">7.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01067</td><td class="data-plain">PE-EL: LEARNING SPIKE: Pivotal Cloud Foundry Training</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain">In Progress</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a development team 
I want to understand PCF's capabilities and how to use them 
So that we can develop web services to deploy there 
  
Notes: 
PluralSight has a good course</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">13.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">0.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01068</td><td class="data-plain">PE-EL: Link Root Cause with TMS and SRI Trailer reporting</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the delivery quality department 
I want to link Root Cause with TMS  
So that we can provide a more accurate Root Cause analysis of failed pkgs by utilizing things such as dispatch and arrival times as well as any reported trailer delays</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01074</td><td class="data-plain">PE-EL: SPIKE: Pre Implementation template</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01392</td><td class="data-plain">PE-EL:  SRI Trailer Multiple screen new dropdown</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the business owner of the Service Reporting Interface 
I want to replace a current drop down for reason code with an explained list of options on the Add, Approve, and Review screens 
So that entry and search functions are easier 
A.C.  
Current Drop down includes ALL, Excludable, Non-Excludable 
New Drop down will include Accident, Breakdown, Dock, Excludable, Linehaul, Material Handling Down Time (MHDT), Outside Carrier, Rail 
This drop down will limit the Reason Drop down selections as listed in the table below 
  
NOTE: 
New drop down matches attached (use the COMPROMISE tab with screen shot, unable to paste here) 
  
  
  
 
 
 
 
 
Current Drop Down/Updated Verbiage 
Service Assurance Alignment / List 
Secondary List 
 
 
1 - Material Handling Down Time 
MHDT 
  
 
 
2 - Packages left on trailer/door 
Dock 
  
 
 
20 - Linehaul Dispatch error 
L/H 
  
 
 
21 - Linehaul Communication/coordination error 
L/H 
  
 
 
22 - Linehaul Failure to meet scheduled run time 
L/H 
  
 
 
23 - Linehaul Driver error 
L/H 
  
 
 
24 - Linehaul trailer dispatched late 
L/H 
  
 
 
25 - Linehaul planned hold 
L/H 
  
 
 
26 - Linehaul Air Ops failure 
L/H 
  
 
 
28 - Linehaul PGH error 
L/H 
  
 
 
3 - Failure to unload timely 
Dock 
  
 
 
30 - Preventable accident 
Accident 
  
 
 
31 - Tractor breakdown 
Breakdown 
  
 
 
32 - FXG Trailer breakdown 
Breakdown 
  
 
 
33 - FXG dolly breakdown 
Breakdown 
  
 
 
34 - Air Ops mechanical 
Breakdown 
  
 
 
35 - Trailer/dolly fire 
Breakdown 
  
 
 
36 - Accident under investigation 
Accident 
  
 
 
4 - Trailer editing errors 
Dock 
  
 
 
42 - Customs delay 
Excludable 
  
 
 
43 - Weather- Storm, tornado, hurricane, snow, ice, etc. 
Excludable 
  
 
 
44 - Power outage, bomb threat, road closure, etc. 
Excludable 
  
 
 
45 - Outside Carrier Accident - Non Preventable 
Excludable 
  
 
 
48 - Rail Carrier Congestion - exempt 
Excludable 
Rail 
 
 
5 - Trailer unloaded in TMS, not physically unloaded 
Dock 
  
 
 
51 - Facility Over Capacity due to Weather - Excludable 
Excludable 
  
 
 
6 - Trailer opened/closed incorrectly in TMS 
Dock 
  
 
 
70 - Outside Carrier Driver related issue 
Outside Carrier 
  
 
 
72 - Outside Carrier Tractor issue 
Outside Carrier 
Breakdown 
 
 
73 - Outsider Carrier Trailer issue 
Outside Carrier 
Breakdown 
 
 
74 - Outside Carrier Accident - Preventable 
Outside Carrier 
Accident 
 
 
75 - Ouside Carrier Hours of Service Issue 
Outside Carrier 
  
 
 
76 - Outside Carrier Slow Run Time 
Outside Carrier 
  
 
 
77 - Outside Carrier Dispatch Error 
Outside Carrier 
  
 
 
79 - Outside Carrier Failed to pickup timely 
Outside Carrier 
  
 
 
89 - Rail Carrier not deramped timely 
Outside Carrier 
Rail 
 
 
9 - Trailer not closed timely 
Dock 
  
 
 
91 - Planned Deferred Rail 
Outside Carrier 
Rail</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01393</td><td class="data-plain">PE-EL: AS/400 Add Shipper field to SVM043-Exclude late pkgs to Dest Zip [MODERNIZATION]</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the delivery quality manager (John Miklos) 
I want to add a field for shipper number in the SVM043 Exclude late pkgs to dest zip maintenance file / screen
so that we can provide a more specific exclusion when shipper number is an option 
A.C 
Shipper number can be added and exclusion for zip only occurs for that shipper's deliveries 
If no shipper number, entire zip excludes 
NOTE: 
Review what Country Code is used for within logic (screen - SVMDF043)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">10.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">10.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01394</td><td class="data-plain">PE-EL: Auto adjustment DB update for SPIKE #232298</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a development team 
I want to repair the performance issues in the  service adjustment DB 
So that bottleneck issues can be corrected  and the determined solution in process before peak adjustment levels can create slow downs 
A.C. 
Determined solution for improvement of upload slow down put in place 
Confirmed reduction in upload time</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01400</td><td class="data-plain">PE-EL: LEARNING SPIKE: Cucumber Training</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain">In Progress</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a development team 
I want to learn Cucumber 
so that I can create automated tests 
  
Notes: 
Probably not a lot of information 
PluralSight doesn't offer much 
May just need to find a good text-based tutorial</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">17.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">4.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01401</td><td class="data-plain">PE-EL: LEARNING SPIKE: Gradle Training</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain">In Progress</td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a Jim 
I want to learn Gradle 
So that I can build quality projects 
  
Notes: 
PluralSight has a good course</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">4.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">0.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01405</td><td class="data-plain">PE-EL: Non excludable Trailer exclusion entries [MODERNIZATION]</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the delivery quality department 
I want non-excluded trailers entered into the SRI to be available for auto status code similar to the proactive weather process 
So that customers (shipper/consignee) have access to potential delays 
AC 
Non-excludable trailers sent to SDRPF100</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01406</td><td class="data-plain">PE-EL: Patch template</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01407</td><td class="data-plain">PE-EL: Post implementation template</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01413</td><td class="data-plain">PE-EL: SPIKE: SK Adjustments to a Weekly Process</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to research if the SK adjustment process can be absorbed into a current weekly or daily adjustment/exclusion process 
So that we can remove a manual process from John Karpinski. 
AC 
Determine if SK adjustment process can fit into a current process 
NOTE: 
If Yes - write story for coding/deploying 
If No - write story for new automated process to be coded</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01415</td><td class="data-plain">PE-EL: SRI Failure Code Rewrite</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of SRI Trailer Reporting 
I want to rewrite the failure code/reason list and reword 51-Over Capacity due to weather-Exclude 
So that it can be independently changed as business needs change.  
AC 
Failure Code 51 is reworded to "Over Capacity due to weather/holiday - exempt" 
Drop down/list is independent</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01639</td><td class="data-plain">PE-EL: Code 67 Logic Change to Exclude Original Barcode and Measure only New [MODERNIZATION]</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to change the logic for Code 67 to Exclude the original barcode/tracking ID and only measure the new relabeled barcode/tracking ID 
So that we are more in line with other FedEx Op-co's processes 
AC 
Original barcode is excluded from service measurement 
New barcode measures from first scan to delivery using that O_D pair Service Standard 
  
NOTE: 
Changed logic 2018.4 to use original HD Service Code to measure.  Do we continue to do that?  Can we measure on the GND relabel?  Work with Bonnie 
What account is the Relabel barcode?  Is it the station 998/889 - if so then some are excluded from service.  Second portion of the shipment will not measure if that is the case.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01642</td><td class="data-plain">PE-EL: Dummy Terminal Screen Changes (MODERNIZATION)</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the delivery quality department 
I want to modify the dummy terminal entry process from two screens to one screen (see note below) 
So that the screen contains the postal code, additional days and Origin/Dest/Both 
A.C. 
Screen contains postal code, additional days &amp; Origin/Dest/Both   
  
Notes: 
File name is SVMPF855 - screen name is SVM855RU (this can be eliminated) 
File name is SVMPF858 - screen name is SVM858RU (this should be modified)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01646</td><td class="data-plain">PE-EL: LEARNING SPIKE: Jenkins/CloudBees Training</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a development team 
I want to learn Jenkins build/deploy tool 
So that I can employ CI/CD to deliver software 
  
Notes: 
Pluralsight has a good course</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01652</td><td class="data-plain">PE-EL: SPIKE: Identify delivery address flag as Commercial / Residential [MODERNIZATION]</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to be able to use the Commercial / Residential flag to measure with instead of Service Code 
So that we can more accurately identify GND/HD volume 
AC 
Learn about the flag 
Determine if it can be brought into Service Measurement (Initial and Commit)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01653</td><td class="data-plain">PE-EL: SPIKE: Package Type in SVM to Utilize New Business Rules  [MODERNIZATION}</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of service measurement 
I want to identify package type as part of service measurement 
So that we can begin to assign different service standards by package type. 
AC 
Determine if we need to have pkg type in service 
Determine how to pull pkg type into service</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01655</td><td class="data-plain">PE-EL: SPIKE: Research Duplicate barcodes (Modernization)</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to research packages flagged as duplicate barcodes as well as packages not flagged but are duplicate barcodes 
So that we can ensure dups are captured and handled in service measurement as business requires 
AC 
Understand current duplicate barcode logic 
Determine impact of non identified duplicates 
If impact, find another way to identify the duplicates</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01656</td><td class="data-plain">PE-EL: SPIKE: RTS pkg automation [MODERNIZATION]</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Service Measurement 
I want to research the ability to identify RTS pkgs that are returning to Shipper warehouses, not shipped from location 
So that we can exclude true returns. 
AC 
Research how to identify returns that return to warehouses by shipper request 
Are return address requests stored by account?</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01658</td><td class="data-plain">PE-EL: SRI Downtime Reporting Change Request</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of the SRI 
I want to have the Downtime reporting section updated to include a checkbox for Entire Sortation System Down 
So that the users of the Downtime reporting can more accurately report issues. 
AC 
Checkbox for Entire Sortation System Down added 
Checkbox for Entire Sortation System Down works 
  
NOTE: 
See attached email with mockup</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01862</td><td class="data-plain">Learn all the things</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 1</td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a person<br><br>
i want to learn<br><br>
so that i may live a fulfilling life<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">All knowledge has been consumed<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01396</td><td class="data-plain">PE-EL: Complete request for Network Appliances ( May not need story; Need to discuss BCDR for LPSAP; Move to 2019.5)</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an architect 
I want to complete the request for network communication systems 
So that we can obtain necessary network infrastructure. 
AC 
Request completed 
Request submitted 
  
NOTE for Kerri: Load balancer request</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01080</td><td class="data-plain">PE-EL:  Request CI Setup IS THIS STILL NEEDED???</td><td class="data-plain"></td><td class="data-plain">PE-EL: KLO Parking Lot GSI</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As an Agile Team 
I want to request CI setup 
So that source code is committed to properly and the CI/CD runway works efficiently 
A.C.: 
 
Software Configuration Management (SCM) is prepared to configure our applications to Jenkins  **Submit request** 
CI/CD Pipeline is setup (automated Built/unit test/deploy)   ****QA test involvement?  QA test environment? 
**Other dependencies???</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Kerri Lindsey</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01469</td><td class="data-plain">Open: TRAINING: KarateDSL</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain">In Development</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer and QA<br><br>
I want to learn KarateDSL<br><br>
So that tests can be created and completed in Karate<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Review Online training documents<br><br></td><td class="data-plain">Shawn Jackson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">13.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">Training</td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">3.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01876</td><td class="data-plain">Open: Implement Enrollment WS Caching Strategy</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a development team I want to implement the caching strategy (determined during spike # 426779) for the enrollment web service<br><br>
So that the application has increased performance  <br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">AC<br><br>
Code &amp; Unit Test integration of Caffeine<br><br>
Application can adhere to caching strategy<br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01033</td><td class="data-plain">Enrollment Web Service Authorization Caching Implementation</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a ReSTful Client, I want the enrollment service to implement a caching strategy for the enrollment web service authorization<br><br>
So that the application has fewer I/O transactions with ESC (Enterprise Security Center) and a performance baseline can be established<br><br>
 <br><br>
Notes:<br><br>
Caching Strategy identified during spike # 426779<br><br>
QA verifies J-Unit tests through Jenkins Jacoco Build report<br><br>
Fewer I/O transactions = transaction went via cache and not ESC<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">AC<br><br>

    1. Code &amp; Unit Test integration of Caffeine<br>
    2. When a client makes a subsequent request, then the authorization information is retrieved from the cache and does not require a transaction with the ESC<br>
    3. Given information is in the cache after a request has been made after <span style="text-decoration: underline;">10 minutes</span>, the information is retrieved from ESC<br>

 <br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01036</td><td class="data-plain">Open: LPSAP Web Service PIF</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a product owner 
I want a PIF completed 
so that application is verified and functional in production. 
A.C. 
-document completed 
-all change request tasks are complete</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01038</td><td class="data-plain">Open: Obtain production credentials</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner 
I want the Development Team to Request Security Certificate for the LPSAP Applications 
So that the Applications Deployed to Production Environment are secured and follow FedEx Standards 
A.C 
1. Request production certificate .p12 
2. Generate the PEM</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01367</td><td class="data-plain">Open: Create LPSAP Business Rules - Facilities</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Product Owner of Service Measurement 
I want to apply Business Rules to the LPSAP enrollment process 
so that Requests can be utilized in Service Measurement 
A.C 
All Origin Facilities must be valid FedEx Ground facilities 
  
 Note: 
1. Update Existing Business Rule in Lpsap Enrollment WebService</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01609</td><td class="data-plain">Open: Create historical table for LPSAP enrollments</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner  
I want to retain Historical LPSAP Enrollments in a Table 
So that I can report on it 
A.C 
1. Request submitted to DBA to create Historical Table</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01610</td><td class="data-plain">Open: Create history table maintenance job #OBTAIN RULES from Kerri</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner I want the LPSAP records to be moved from Active Table to Historical Table<br><br>
So that the Active Table Size is kept Optimum levels<br><br>
Note: Additional Information required from Business Owner<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01612</td><td class="data-plain">Open: Deploy enrollment tables to production</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner 
I want the LPSAP Active &amp; Historical Tables to be Deployed to PROD 
So that I can begin entering LPSAP Requests in the Modernized System 
  
A.C 
1. Task added to EPDSM Request to Deploy LPSAP Tables to PROD</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01614</td><td class="data-plain">Open: Integrate Fortify into Pipeline for WS &amp; UI</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a development team 
I want to integrate Fortify for WS &amp; UI into Pipeline 
So that our LPSAP Application can be compliant with FedEx Security Standards. 
A.C 
1. Jenkins Pipeline is Modified to Include Fortify Scan</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01615</td><td class="data-plain">Open: Jenkins configuration with SCM</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner  
I want the Development Team to Coordinate with the DevSecOps Team 
So that the Jenkins file is in sync with SCM standards so that we can use it to deploy our Application (LPSAP-WS &amp; LPSAP-MAINLINEHOT-WS) to Production 
A.C 
1. Setup LPSAP-WS &amp; LPSAP-MAINLINEHOT-WS in Jenkins Release Management 
2. New Jenkins file setup if necessary 
3. Jenkins File ready for deploying the Applications to Production 
Note : 
Identify the process for Automated Deployments to QA</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01617</td><td class="data-plain">Open: LPSAP WS QA Deployment</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Product  Owner 
I want the LPSAP WS to be Deployed to the QA Environment 
So that we can begin testing the WS 
A.C 
1. WS deployed to QA via Jenkins Pipeline 
2. WS can be queried through Postman or Browser (any client) 
Note : 
Contact Cloud Dojo to Identify the Release Space</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01619</td><td class="data-plain">Open: Request Deploy LPSAP enrollment tables to QA</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a QA Analyst 
I want the LPSAP Active &amp; Historical Tables to be Deployed to QA 
So that we can begin Testing the application in QA 
  
A.C 
1. EPDSM Request to Deploy LPSAP Tables to QA</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01620</td><td class="data-plain">Open: Request ESC for QA and Production environment</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Product Owner 
I want to restrict access to the LPSAP WS 
So that only authorized clients can access the information on the WebService 
A.C 
1. Request ESC Setup for QA Environment 
2. Request ESC Setup for Prod Environment</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01621</td><td class="data-plain">Open: Request Production Deployment</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a product owner 
I want to deploy LPSAP web service to production 
So that it starts providing business value. 
A.C. 
-authorization for go/no go received</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01622</td><td class="data-plain">Open: Setup ESC for QA and Production</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner 
I want to Create Roles in ESC to be able to Restrict Access to the LPSAP WebService 
So that only Authorized Users have access 
A.C 
1. Create Roles in ESC for QA 
2. Create Roles in ESC for Prod</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01623</td><td class="data-plain">Open: SPIKE - Research BO universe setup</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Business Owner 
I want the LPSAP Active &amp; Historical Tables added to the Universe 
So that I can Analyze Enrollment Information 
A.C 
1. Contact the BO team about adding the tables to the Universe</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01845</td><td class="data-plain">Open: SPIKE Research Fortify</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Product Owner 
I want the Development Team to research fortify 
so that the Application is compliant with Fedex Security Standards 
A.C 
1. Contact Cloud Dojo Team for Onboarding process 
2. Document the onboarding process for the application 
Note: 
Submit onboarding  request if needed</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01847</td><td class="data-plain">Open:  Set up AppD dashboard for the webservice &amp; UI in QA</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a development team 
I want to set up monitors in AppD 
So that we can be notified of unusual activities and evaluate webservice performance 
AC 
KPIs identified (How Many requests, Response time, Time of Day, Overall Volume) 
Dashboard configured 
Monitors set up</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01873</td><td class="data-plain">Open: Spike Data Retention on LPSAP Enrollment Tables</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a team<br><br>
I want to deciede on when to move records from the active table to the historical table<br><br>
so that data size is maintained<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Documented strategy<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01875</td><td class="data-plain">Implement UI Caching Strategy</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a LPSAP user<br><br>
I was the UI to cache station name and abbreviations, shipper number names<br><br>
so that UI is responsive<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">AC<br><br>
UI adheres to caching strategy<br><br>
UI shows minimal lag time ('under 2 seconds' approx.)<br><br>
 <br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02081</td><td class="data-plain">Mainline Hot Service Auth</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a <br><br>
I want the LPSAP mainline hot service to be protected by authentication and authorization<br><br>
So that only authorized users can see the data<br><br>
 <br><br>
Note:<br><br>
Separate auth library from enrollment web service<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Given an invalid user, when the mainline hot service is accessed, then an authorization error is returned<br><br>
Given a valid user, when the mainline hot service is accessed, then no authorization error is returned<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02107</td><td class="data-plain">Integrate Customer Account Lookup Into Web Service</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP1.1: Create Reusable Service Interface for Daily LPSAP Process</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an enrollment web service ,<br><br>
I want to verify the account number on a late pickup request, so that only valid FedEx Enterprise Account Numbers are stored<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01863</td><td class="data-plain">TRAINING: Fortify</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain">Ready for PO Review</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer<br><br>
I want to learn FORTIFY<br><br>
So that I can scan applications for security vulnerability<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Know how to add to project<br><br>
Know what Fortify does<br><br></td><td class="data-plain">Shawn Jackson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount">8.50</td><td class="data-amount">3.50</td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">Training</td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">4.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02080</td><td class="data-plain">Enabler - Customer Account Infomation</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a developer<br><br>
I want to define the query and source of the look up of the Ground Shipper Number to  Enterprise Account Number  cross reference<br><br>
So that the Enterprise Account Number and Name are retrieved from the data store.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Interface is defined and documented<br><br>
Source is defined and doucumented<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01963</td><td class="data-plain">Create Customer Account Lookup Client</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As the LPSAP authorized entry user<br><br>
I want to have my entered shipper numbers verified<br><br>
So that all requests contain valid shipper names and Enterprise Account Numbers (EAN)<br><br>
 <br><br>
Note: Use Oracle database<br><br>
 <br><br>
 <br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">
    1. when  a  valid Ground account #, then provide account name and enterprise account number. <br>
    2. when a  valid Enterprise account #,  then provide account name and enterprise account number.<br>
    3. when an invalid Enterprise or Ground account #,  the provide empty response<br>

 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01837</td><td class="data-plain">Integrate Customer Account Lookup into User Interface</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As the owner of LPSAP (Late Pickup Shipper Approval Process)<br><br>
I want to Integrate customer account lookup into LPSAP Web Service<br><br>
So that we are only storing Enterprise Account Numbers (EAN) for valid accounts <br><br>
 <br><br>
Note:<br>Confirm where the EAN will be stored<br><br>
IBMi:<br><br>
- If existing customer, the 7-digit GSN is stored.<br><br>
- If new customer, the 9-digit EAN is stored.<br><br>
- These are validated via MKTPF520<br><br>
- Existing/New defined based on GSNE timing<br><br>
Contact Mark Menanno to review CI questions regarding EAN (possible contact)<br><br>
 <br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">AC:<br><br>

    1. Account information sent to CI upon entry<br>
    2. Account information is retrieved from CI<br>
</td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">16.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">16.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02105</td><td class="data-plain">Mainline Hot Location Client integration to UI</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a user interface<br><br>
I want to access the mainline hot service<br><br>
So that I can verify origin locations and add mainline hot lanes to the request<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Retrieve information for entered station<br><br>
Retrieve information for entered district<br><br>
Mainline hot information added to the request<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain">B-02104</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02104</td><td class="data-plain">Enrollment WS Client integration to UI</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a user interface<br><br>
I want to be able to access the LPSAP enrollment webservice<br><br>
So that I can have a persistence resource to create, read, and update enrollment requests and submit requests to service measurement<br><br>
 <br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">pass creation/update information<br><br>
retrieve stored information<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">B-02105,B-02109</td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02109</td><td class="data-plain">Create Security Token Generator for User Interface</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.1 Web Service Integration</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a User Interface<br><br>
I want a token generator<br><br>
So that I can use a token to authenticate with all LPSAP web services<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">User Interface application can generate a valid token<br><br>
User Interface can add the token to a cookie<br><br>
User interface can access the token<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain">B-02104</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01864</td><td class="data-plain">SPIKE: Sonar/Java Script</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">Ready</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a development team<br><br>
I want to identify integration points so that we can have the user interface project integrated with Sonar <br><br>
So that code metrics are visible in Sonar Qube <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Integration points identified<br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount">6.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">6.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01046</td><td class="data-plain">PE-EL: LEARNING SPIKE: Test Karate with Practice Test Cases</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">In Test</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">s a QA analyst 
I want to utilize KarateDSL to create test case scenarios in Gherkin syntax 
So that we are creating automated tests 
AC 
At least 1 test case created 
At least 1 test case executed 
At least 1 test case passes 
  
Note 
Mainline hot web service can be used for this</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">12.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">3.00</td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01632</td><td class="data-plain">PE-EL: TRAINING: Typescript</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer<br><br>
I want to learn Typescript<br><br>
So that I better understand the Angular application<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Course completed<br><br></td><td class="data-plain">Shawn Jackson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">5.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">10.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01630</td><td class="data-plain">PE-EL: TRAINING: Karma (Angular)</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">Ready for PO Review</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer<br><br>
I want to learn Karma<br><br>
So that I can learn to test Angular components<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Course completed<br><br></td><td class="data-plain">Shawn Jackson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">2.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">0.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01053</td><td class="data-plain">PE-EL: TRAINING: User Experience Design</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">In Development</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer <br><br>
I want to improve user experience design<br><br>
So that the business is incorporated more into the solutions<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Plural sight videow - UI Tips and Tricks (https://app.pluralsight.com/library/courses/ux-tips-tricks-developers)<br><br>
 <br><br>
Complete course<br><br></td><td class="data-plain">Paul Ray</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">15.00</td><td class="data-amount">4.00</td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">15.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01485</td><td class="data-plain">PE-EL: Training: App Dynamics integration to Ecma Script</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">In Development</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer.<br><br>
I want to learn about AppD integration into a Ecma Script application<br><br>
So that ES applications can be integrated in AppD monitoring<br><br>
 <br><br>
Operational Mobility see the miscellaneous links  (https://work.purplehub.fedex.com/sites/OperationalMobility/SitePages/guide.aspx)<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Know how to use KPI's for AppD with Java script<br><br></td><td class="data-plain">Paul Ray</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">4.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">4.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01714</td><td class="data-plain">Open: TRAINING: Protractor e2e</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">In Progress</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer<br><br>
I want to learn protractor<br><br>
So that I can write End to End user tests<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">watch video<br><br>
 <br><br></td><td class="data-plain">Paul Ray</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">4.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">4.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01484</td><td class="data-plain">PE-EL: TRAINING: Angular Material Course and Library Familiarity</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">In Progress</td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a UI developer<br><br>
I want to learn Angular Material<br><br>
So that I can develop a website on modern principles and fully utilize components compatible with Operation Mobility Group developed components.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Course completed<br><br></td><td class="data-plain">Shawn Jackson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">14.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">6.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01047</td><td class="data-plain">PE-EL: TRAINING: Angular (Started in PI5 IP Sprint)</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain">In Development</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a developer<br><br>
I want to learn Angular<br><br>
So that we work on the LPSAP UI<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">HTTP request<br><br>
Forms<br><br>
 <br><br>
 <br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount">16.00</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount">11.00</td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01384</td><td class="data-plain">PE-EL: TRAINING: CSS/SCSS</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01385</td><td class="data-plain">PE-EL: TRAINING: Intro Operational Mobility</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01387</td><td class="data-plain">PE-EL: TRAINING: NPM Overview</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 5</td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02154</td><td class="data-plain">Thumbnail List</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a resolving user,<br><br>
I want the resolve screen to have a list of thumbnail views of requests<br><br>
So that I can quickly view items in my selected location or district<br><br>
 <br><br>
Note:<br><br>
Listed requests are pending approval<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Thumbnail component includes shipper, origin, and pickup dates<br><br>
Thumbnail list component created<br><br>
Thumbnail list filters by station<br><br>
Thumbnail list filters by district<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02155</td><td class="data-plain">Request Details</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a resolving user<br><br>
I want the resolve screen to display request details<br><br>
So that I may accurately resolve or deny each request<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Details of selected request are displayed including...<br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01380</td><td class="data-plain">Request Resolution</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.2: Create User Interface for Late Pickup Resolution</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an authorized user,<br><br>
I want to be able to provide approval or denial of a pending request<br><br>
So that late pickup requests may be inputs to Service Measurement<br><br>
 <br><br>
Notes:<br>District &amp; PGH personnel<br><br>
Commit date = the date we committed to deliver by or else MBG will be paid if applicable<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Decisions made on requests are sent to the enrollment web service<br><br>
Requests can be approved<br><br>
Requests can be denied<br><br>
Reqeusts are removed from the list after decision is provided <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01846</td><td class="data-plain">PE-EL:  Set up AppD dashboard for the UI</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.3: Create User Interface for Late Pickup Review</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a development team 
I want to set up monitors in AppD 
So that we can be notified of unusual activities and evaluate UI performance 
AC 
KPI identified. 
Dashboard configured 
Monitors set up 
  
  
NOTE: Sean D. may be able to assist in choosing KPIs</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02156</td><td class="data-plain">List of Requests</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.3: Create User Interface for Late Pickup Review</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a LPSAP user<br><br>
I want to see a list of entered requests on the review screen<br><br>
So that I can learn what requests exist and the status of each request<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Head and body of collapsible detail component created<br><br>
Requests show as a list<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02157</td><td class="data-plain">Request Filter</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.3: Create User Interface for Late Pickup Review</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a LPSAP user<br><br>
I want to be able to filter requests on the review screen<br><br>
So that I can see only the requests that are important to me<br><br>
 <br><br>
Note:<br><br>
District/location may be a single, interchangeable field<br><br>
must decide which fields can be searched in conjunction and specific implementation<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Filter by shipper<br><br>
Filter by district<br><br>
Filter by station/hub<br><br>
Filter by date (must fill in one of the above, then this is optional)<br><br>
Filter by status/pending (?)<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02159</td><td class="data-plain">Refactor Components</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.3: Create User Interface for Late Pickup Review</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a developer<br><br>
I want to refactor the screens<br><br>
So that the components are harmonious<br><br>
 <br><br>
Note:<br><br>
Consolidate components where possible<br><br>
Clear distinctions where not<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Refactor</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01848</td><td class="data-plain">PE-EL: Create WSSO Filter for LPSAP UI</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.4: User Interface Security for LPSAP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Development Team 
We want to Create WSSO filter for LPSAP UI 
So that we can restrict only authenticated users to access the application 
A.C 
1. Create WSSO Filter 
2. Allow only Authenticated users to access the application.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01849</td><td class="data-plain">PE-EL: Integrate WSSO for UI with thymleaf</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.4: User Interface Security for LPSAP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Development Team 
We want to Integrate WSSO with Thymleaf 
So that the authentication details of the user logged in can be passed to the Angular Application 
A.C 
Show the signed in user ID on the application bar</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02103</td><td class="data-plain">Enterprise Group Retrieval Service Client</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.4: User Interface Security for LPSAP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a user interface,<br><br>
I want to be able to retrieve user groups(roles) from the enterprise group retrieval service (EGRS)  so that I can identify the role of the current user.<br><br>
 <br><br>
Background :<br><br>
The user interface wants to know the group of the user so it can make decisions on what screen to present.<br><br>
Note :<br><br>
FedEx Ground Users include : Company Code = FedEx Ground and Country = US + CA<br><br>
FXG Users with resolve include : all of the above + department id's (TBD) <br><br>
FedEx Services Users include : Company Code = FedEx Services and Country = US<br><br>
FXS Users with maintenance include : all of the above + department id<br><br>
Group Document needs to be updated to add .<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Given a FedEx Ground user when the user is authorized then the service will retrieve all groups the user belongs to<br><br>
Given a FedEx Ground user with resolve privileges when the user is authorized then the service response should include the resolve group<br><br>
Given a FedEx Ground user with entry and review privileges when the user is authorized then the service response should include the entry and review group.<br><br>
Given a FedEx Services user with maintenance privileges when the user is authorized then the service response should include the maintenance group.<br><br>
Given a FedEx User without any privileges when the user is authorized then the service response should include an empty list.<br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02106</td><td class="data-plain">EGRS Client Integration with user interface</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP2.4: User Interface Security for LPSAP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a user interface <br><br>
I want to access the Enterprise Group Retrieval Service client<br><br>
So that I only present the authorized options for each user.<br><br>
 <br><br>
Notes:<br><br>
Perform call on log in in spring boot controller<br><br>
Cache groups<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Active user's group is determined<br><br>
only resolve users can see the resolve page<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain">Functional</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01625</td><td class="data-plain">PE-EL Flag blacklist account review</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP3: Notification of Interest Publisher</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As as Resolver I would like a visual indicator that the request is for a shipper on the list of scrutiny<br><br>
So that I am prevented me from approving requests that are for accounts under scrutiny<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/07/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01839</td><td class="data-plain">PE-EL: Create interface to NOI Publisher  (LPSAP1.1 or 5 ??)</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP3: Notification of Interest Publisher</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Development Team 
we want to create interface for NOI publisher 
so that the Notifications can be sent</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01852</td><td class="data-plain">PE-EL - Multiple destination entry capability for UI</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: LPSAP3: Notification of Interest Publisher</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Requester 
I would like to enter multiple destinations.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01853</td><td class="data-plain">PE-EL Keep repeatable fields options for rapid fire entry</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP3: Notification of Interest Publisher</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Requester 
I would like to have repeatable fields  
to allow for rapid fire entry</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01854</td><td class="data-plain">PE-EL Location field accept Alpha or Numeric location designation</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP3: Notification of Interest Publisher</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Requester  
I would like to enter Alpha or Numeric in the locations field 
to use the vernacular location</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01855</td><td class="data-plain">PE-EL - Enchanment - Approver groups by district</td><td class="data-plain"></td><td class="data-plain">PE-EL: LPSAP3: Notification of Interest Publisher</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As a Resolver 
I would like to be in a special group of approvers alligned by district. 
So that I am only presented with request requireing resolve form my district</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01860</td><td class="data-plain">IBMi: Explanation of DCAL problem scenario</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PE-EL: Short term solution for pickup date and origin (DCAL)</td><td class="data-plain"></td><td class="data-amount">0.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an owner of commit date 
I want to transfer knowledge of DCAL problems 
So that a work around solution can be created for Monday Residential/Commercial and Direct Inject 
A.C. 
Provide track ids 
Provide scenarios 
Provide explanation</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Kerri Lindsey</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02151</td><td class="data-plain">Monday Commercial CLS Rule Test</td><td class="data-plain"></td><td class="data-plain">PI19.2 Small High Value</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Commit and Service Measurement<br><br>
I want to test CLS rules because we are changing which items can pass into the calendar service via the CIM (Runs with Scissors)<br><br>
So that it can be ensured that commit date(s) are accurate and that Service will measure correctly before changes are in production<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Test GND Service Codes against calendars<br><br>
Test SP Service Codes against calendars<br><br>
Test HD Service Codes for 1-2 day lanes against calendars<br><br>
Test HD Service Codes for 3+ day lanes against calendars<br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02153</td><td class="data-plain">SPIKE: Dynamic Threading</td><td class="data-plain"></td><td class="data-plain">PI19.2 Small High Value</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As the owner of Commit and Service Measurement<br><br>
I want to research how to create dynamic threads<br><br>
So that threads will activate and close as needed based on volume<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Research completed<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Peak Elevation</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02128</td><td class="data-plain">Predictive EDD Modeling</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Predictive EDD Modeling</td><td class="data-plain">In Progress</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Evaluate the Predictive EDD modeling already develped to determine future design potentials so that when EDD roadmap foundational components are developed, the Predictive EDD design is known and up to date<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Erika Lynn Paulson</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01911</td><td class="data-plain">PSSC: Spike: HA / DR Strategy: Research the current strategy</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PSSC: Define DnA HA/DR Strategy</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to research how the DnA applications are currently implementing HA/DR so that we can clearly define the new HA/DR Strategy.<br><br>
NOTES: <br>What Applications need HA?<br>Understand the current DR strategy? <br>Are there any currently defined DR expectations (Shatara, mgmt team?)<br><br>
 <br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01912</td><td class="data-plain">PSSC: Spike: HA / DR Strategy: Research corporate objectives and SLA&#39;s</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">PSSC: Define DnA HA/DR Strategy</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to research any corporate objectives and SLAs so that we can understand how it might tie to a Google Solution.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01913</td><td class="data-plain">PSSC: Op Ex: Document HA Strategy - Initial Version</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 3</td><td class="data-plain">PSSC: Define DnA HA/DR Strategy</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to create a document with the initial HA Strategy so that we can share it with key stakeholders to obtain feedback.<br><br>
NOTES:  <br>Who are the key stakeholders?  Mgmt &amp; architects?  Others?<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01914</td><td class="data-plain">PSSC:  Op Ex: Document DR Strategy - Initial Version</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 3</td><td class="data-plain">PSSC: Define DnA HA/DR Strategy</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to create a document with the initial DR Strategy so that we can share it with key stakeholders to obtain feedback.<br><br>
NOTES:  <br>Who are the key stakeholders?  Mgmt &amp; architects?  Others?<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02229</td><td class="data-plain">PSSC: System Team: Creating Change Request as requested by</td><td class="data-plain"></td><td class="data-plain">PSSC: KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As every user need a PDSM  change requests for for their changes to move prod environment.<br><br>
These tasks owned by system team make sure they are inline with PDSM process<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> - create PDSM change resuest<br><br>
 - While creating PDSM, is all the data is relevant and can be understood by CAB team and others<br><br>
 - Make sure assign to the right group<br><br>
 - Make sure get Manger and IT MD approval<br><br>
 - Follow up for approvals from IT Manager, IT MD and CAB team<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02230</td><td class="data-plain">PSSC: System Team: -	Audit on PPM/Go-NO Go-NO</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 1</td><td class="data-plain">PSSC: KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Audit on PPM/Go-NO Go-NO<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> - Make sure All required information is put up in PPM and Go/NO forms in PPM site<br><br>
 - All requirements are compliance<br><br>
 - Code review is compliance<br><br>
- Code version is aligned in the document?<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02231</td><td class="data-plain">PSSC: SYtem Team: Follow up on approval process for CRs</td><td class="data-plain"></td><td class="data-plain">PSSC: KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Follow up on approval process for CRs<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> - Follow up for approvals from IT Manager, IT MD and CAB team<br> - Make sure get Manger and IT MD approval<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02236</td><td class="data-plain">PSSC: SYstem Team: Installations as needed (ex: Gurobi server)</td><td class="data-plain"></td><td class="data-plain">PSSC: KLO</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Installations as needed (ex: Gurobi server)<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"> - Make sure all request has to fulfill installations as needed (ex: Gurobi server)<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/20/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01903</td><td class="data-plain">PSSC: Metadata 1.0 Data Catalog MVP Evaluation</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PSSC: Metadata 1.0</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>GCP DC Review \ Evaluate additional options (Excel link to O365 via PurpleHub, or table in GCP)</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>1) Evaluate Google Data Catalog for fullness of functionality to achieve MVP</span><br><br>
<span>2) Determine appropriate additional options for MVP for Data Catalog with recommendations listed</span><br><br>
 <br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01904</td><td class="data-plain">PSSC: Metadata 1.0: Determine Metadata Capture Strategy</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">PSSC: Metadata 1.0</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Work with ingestion/integration team leads on Metadata capture strategy including technical metadata tracking specifically high level source details</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>0.5) Subtasks to be created for individuals on Ingestion/Integration teams for their time on this story</span><br><br>
<span>1) Determine metadata capture process with input from ingestion/integration teams, document this process from both current MVP state as well as future state (modified from current Metadata strategy document)</span><br><br>
<span>2) Document is reviewed and approved by PSSC and Architecture teams</span><br><br>
<span>3) Document is published to DnA Site</span><br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01905</td><td class="data-plain">PSSC: Metadata 1.0: Add metadata catalog, business glossary to Metadata Whitepaper</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 4</td><td class="data-plain">PSSC: Metadata 1.0</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Add metadata catalog, business glossary to Metadata Whitepaper</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>1) Metadata whitepaper is Consolidated/updated with details from current metadata documents, business glossary etc.</span><br><br>
<span>2) Document is reviewed/approved by PSSC and Architecture Team</span><br><br>
<span>3) Document is added/updated on DnA Site</span><br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">B-02210</td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02210</td><td class="data-plain">PSSC: Metadata 1.0 Glossary of Terms Policy</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">PSSC: Metadata 1.0</td><td class="data-plain">In Progress</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Develop a policy<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Acceptance:<br><br>

    1. Glossary of Terms policy is created<br>
    2. It's reviewed by PSSC, and feedback incorporated<br>
    3. It's published (repository TBD)<br>
    4. DnA is made aware of the policy<br>
</td><td class="data-plain">Alex Ovchinnikov</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain">B-01905</td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01902</td><td class="data-plain">PSSC: Op Ex: Upload all data infrastructure documents to Purple Hub</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 5</td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Post the finalized documents to the Purple Hub for access to all DnA Teams<br><br>
 <br><br>
1. Data Privacy Policy <br><br>
2. Metadata<br><br>
3. Data Security MVP<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02028</td><td class="data-plain">PSSC: Op Ex: GCP Applications Alerting &amp; Monitoring: Complete  Current State Assessment</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to complete a current state assessment of the Operational Metrics &amp; Reporting applications so that we know the current state of monitoring and alerting.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02029</td><td class="data-plain">PSSC: Op Ex: GCP Apps Alerting &amp; Monitoring: Current State Assessment for other DnA Apps</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to complete a current state assessment of the DnA applications so that we know the current state of monitoring and alerting.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02030</td><td class="data-plain">PSSC: Op Ex: GCP Apps Alerting &amp; Monitoring: Document Standards and best practices</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to document standards and best practices for GCP monitoring and alerting solutions so that we can provide the DnA teams with appropriate guidelines for GCP moving forward.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02031</td><td class="data-plain">PSSC: Op Ex: DnA Purple Hub: Determine Standards / Best Practices</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to meet with the PSSC team and the architects to determine the standards to be used for the DnA PurpleHub so that we can create a Standards/Best Practices document.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02032</td><td class="data-plain">PSSC: Op Ex: DnA Purple Hub: Document Process to request changes</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to create a document with DnA PurpleHub information so that the DnA Team can easily request PurpleHub changes.<br><br>
NOTES:<br>The following items are identified:<br> - How to request a change<br> - Type of change needed:<br>   - New page<br>   - Change to existing page<br>   - other changes?  (identify changes)<br> - Instructions on how to access new page<br> - what else??????<br><br>
Where should this reside on the DnA PurpleHub?<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">All identified items have been clearly defined in the document <br>A formal request process has been created <br>The formal request process has been published to the DnA PurpleHub<br><br>
 <br><br>
 <br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02033</td><td class="data-plain">PSSC: Op Ex: PurpleHub:  Design/create/publish the new Architecture page</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team we want to meet with the architects to determine what should be displayed on the Architecture page of the DnA PurpleHub so that we can design/create/publish the new Architecture page.<br><br>
Tasks:  <br>Meet with Architects to determine what should be included on Architecture page<br>Design/create Architecture page<br>Publish Architecture page<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">Acceptance Criteria:  <br>Architects approve contents/design of Architecture page<br><br>
DoD:  <br>Architecture page is published to the DnA PurpleHub<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02034</td><td class="data-plain">PSSC: Op Ex: PurpleHub: Create new Standards/Best Practices document</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to create a Standards/Best Practices document for each new standard/policy that is created throughout the PI.<br><br>
NOTES:<br>Support Model Strategy<br>App Gap Analysis with Strategy<br>Monitoring/Alerting Standards<br>what else?<br><br>
Should these be their own stories?<br>Where should they get published?<br>Do we create a new Policies, Procedures, &amp; Standards page?<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02035</td><td class="data-plain">PSSC: Op Ex: Operational Support Model: Establish Current State</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to evaluate the current metrics being used to monitor/support DnA apps so that we can can establish a current state.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02036</td><td class="data-plain">PSSC: Op Ex: Spike: Operational Support Model: Gap Analysis on the List of DnA apps collected through the score card</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to create the list of all current DnA applications so that it can be used in the gaps analysis matrix.<br><br>
Notes: Collaborate with DnA teams (Deep, Josh, Michael Fritts, and Shatara) to define what those apps are.<br>This is dependent on how the App Rat Scorecards are completed.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02037</td><td class="data-plain">PSSC: Op Ex: Spike: Operational Support Model: Define Support Categories Needed</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">3.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to define the support categories needed so that we can develop the Support Model.<br><br>
NOTES:  testing, tickets, install follow-up, KLO, etc.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain">Spike</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02038</td><td class="data-plain">PSSC: Op Ex: Spike: Operational Support Model: Define Support Levels</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to define the support levels so that we can develop the model to be used by the DnA Train.<br><br>
NOTES:  <br>L0, L1, L2, L3, L4<br>Are there FedEx standards that we can follow?<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02039</td><td class="data-plain">PSSC: Op Ex: Operational Support Model: Determine Primary Type of Support for all DnA Applications</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to categorize all DnA applications so that we can determine the primary type of support required for each application.<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02040</td><td class="data-plain">PSSC: Op Ex: Operational Support Model: Document High Level Strategy</td><td class="data-plain"></td><td class="data-plain">PSSC: OpEx: MVP</td><td class="data-plain"></td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">As an Ops Excellence Team, we want to document a high level strategy to implement the best support model for all DnA apps<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02129</td><td class="data-plain">RLGL Algorithm 2.0</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">RLGL Algorithm 2.0</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Determine architecture framework and POC improvement of current version RLGL so it can be automated, increase static diverts, and provide a framework for productionalizing models<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Angela Kao</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02130</td><td class="data-plain">Safety Dashboard</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Safety Dashboard</td><td class="data-plain">In Progress</td><td class="data-amount">8.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Assist Safety and Analytics team to move developed dashboard to QA, and Production so that safety metrics insights can be visualized across many different users<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Jose Zenteno</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02131</td><td class="data-plain">Safety Modeling</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Safety Modeling</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Engage Safety and Analytics team to further refine WorkRight modeling and multiple behavioral hypothesis so that actionable results can be taken<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Divya Virender Kumar</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01908</td><td class="data-plain">PSSC: Data Security MVP Documentation: Create Living Data Security Document</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 2</td><td class="data-plain">Security</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"><span>Consult with Eric (Jay on obfuscation) to create Living Data Security Document to address current security state and user authorization, and proposing future state</span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span>1) Create whitepaper to document current state and proposed future state of Data Security, including as much detail as known for future tooling</span><br><br>
<span>2) Document is uploaded/updated to DnA site</span><br><br></td><td class="data-plain">Jordan Olp</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/18/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/12/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01838</td><td class="data-plain">Design Account Strategy</td><td class="data-plain"></td><td class="data-plain">Service Analytics Transition</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext">As a: Manager of Data Ingestion 
  
I want: Technical alternatives to automate running shell scripts 
  
So that: We can automate Service Analytics Shell Scripts 
  
Test plan: 
Verify the orchestration design with existing Architects 
Verify orchestration design with existing DBA(s)  
Acceptance Criteria: 
Preferred design is selected by Oracle Physical DBA 
Preferred design is selected by Hadoop Administrator 
Preferred design is selected by FedEx Ground Big Data Architect(s)</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Advanced Analytics Anonymous (AAA)</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01840</td><td class="data-plain">App Account Creation</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">Service Analytics Transition</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a: Developer 
  
I want: Data Migrated under a User ID not maintained by 1 particular individual 
  
So that: Automated Scripts would without requiring intervention from an individual. 
  
Test plan: 
Scripts run with the same results as they currently do today. 
Acceptance Criteria: 
Scripts run with the same results as they currently do today.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01841</td><td class="data-plain">Modify Scripts for proper authentication.</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">Service Analytics Transition</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a:Developer 
  
I want: To modify the current scripts  
  
So that: The scripts successfully execute. 
  
Test plan: 
Modified script executes to the same results as existing scripts that are manually run. 
Acceptance Criteria: 
 
Modified script executes to the same results as existing scripts that are manually run.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01842</td><td class="data-plain">Enhance Logging</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 5</td><td class="data-plain">Service Analytics Transition</td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain">FXG - DnA CY19 PI1</td><td class="data-longtext">As a: Developer 
  
I want: Enhanced Logging 
  
So that: we log success , more detailed failures, and remove false/positives. 
  
Test plan: Success Logs 
Detailed Failures 
No More False/Positives 
Acceptance Criteria: 
 Level of Detail in a Log File.</td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/08/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-01874</td><td class="data-plain">PSSC: Update the MVP Roadmap for Cloud Security &amp; Governance</td><td class="data-plain">FXG DnA CY19 PI1 Iteration 1</td><td class="data-plain">Team Roadmaps 19.2</td><td class="data-plain"></td><td class="data-amount">2.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Update the Roadmap that was created in PI19.1, so that we can align all the efforts within the DnA Train and keep business informed of the timing of key deliverables<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext">MVP Roadmap updated with,<br><br>
1) Known timelines as of PI2<br><br>
2) Known deliverables as of PI2<br><br>
Get this signed off by Leadership team and communicate this to the rest of DnA Teams<br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/14/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/11/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02101</td><td class="data-plain">PSSC: App Rationalization: Update the major and minor milestones for 19.2</td><td class="data-plain"></td><td class="data-plain">Team Roadmaps 19.2</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Update the MVP Roadmap for App Rationalization<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02102</td><td class="data-plain">PSSC: Op Ex: Determine major and minor milestones for PI 19.2</td><td class="data-plain"></td><td class="data-plain">Team Roadmaps 19.2</td><td class="data-plain"></td><td class="data-amount">1.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext"></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Paper Street Soap Company</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain">Standard</td><td class="data-plain">B-02006</td><td class="data-plain">PROD: Update CDC PDS311F and EAS301F subs in prod</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Testing CDC with Kafka</td><td class="data-plain">Ready</td><td class="data-amount">5.00</td><td class="data-plain">FXG - DnA ART</td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">As a Manager of the DIRE application</span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">I want the CDC subscription that replicates the PDS311F and EAS301F files from DIRE to CDAS and from DIRE to DCOO updated with the 2 new columns. </span><br><br>
<span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">So that the DIRE information needed in CDAS and DCOO can continue to be replicated real-time. </span><br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"><span style="color: #5a5a5a; font-family: 'arial' , sans-serif; font-size: 10pt;">Acceptance Criteria:</span><br><br>
<span style="color: #5a5a5a; line-height: 106%; font-family: 'arial' , sans-serif; font-size: 10pt;">The 6 CDC subscriptions are updated with the new columns in the prod environment.</span><br><br></td><td class="data-plain"></td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/13/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - I shipped my pants</td><td class="data-amount"></td><td class="data-plain">NFR</td><td class="data-plain"></td>
		</tr><tr>
			<td>Blocking RIDAs: 0</td><td class="data-plain"></td><td class="data-plain">B-02132</td><td class="data-plain">Weight-Dim-EPDI Dashboard</td><td class="data-plain">FXG DnA CY19 PI2 Iteration 1</td><td class="data-plain">Weight-Dim-EPDI Dashboard</td><td class="data-plain">In Progress</td><td class="data-amount">13.00</td><td class="data-plain">FXG - DnA CY19 PI2</td><td class="data-longtext">Determine scope and framework around a weight, dim, and EPDI dashboard giving the business clear visibility insights<br><br></td><td></td><td class="data-plain"></td><td class="data-longtext"></td><td class="data-plain">Angela Kao</td><td></td><td class="data-plain"></td><td></td><td></td><td class="data-date">03/19/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-date">03/15/2019</td><td class="data-date"></td><td class="data-amount"></td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain">Future</td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain"></td><td class="data-plain">FXG - DnA - Data Science</td><td class="data-amount"></td><td class="data-plain"></td><td class="data-plain"></td>
		</tr>
	</tbody>
</table></td>
			</tr>
		</table>
		
	</body>
</HTML>
